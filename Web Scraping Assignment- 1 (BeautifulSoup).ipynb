{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Header Tags from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requests to server\n",
    "page= requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading page content \n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = soup.find('span', class_='mw-headline')\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping wikipedia header\n",
    "wikiheader= []\n",
    "for i in soup.find_all('span',class_='mw-headline'):\n",
    "    wikiheader.append(i.text)\n",
    "wikiheader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikiheader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Wikiheader\n",
       "0  From today's featured article\n",
       "1               Did you know ...\n",
       "2                    In the news\n",
       "3                    On this day\n",
       "4       Today's featured picture\n",
       "5       Other areas of Wikipedia\n",
       "6    Wikipedia's sister projects\n",
       "7            Wikipedia languages"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making DataFrame\n",
    "Header_Tag= pd.DataFrame({'Wikiheader':wikiheader})\n",
    "Header_Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- IMDB's Top rated 100 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requests to server\n",
    "page= requests.get('https://www.imdb.com/list/ls091520106/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3 class=\"lister-item-header\">\n",
       "<span class=\"lister-item-index unbold text-primary\">1.</span>\n",
       "<a href=\"/title/tt0111161/\">The Shawshank Redemption</a>\n",
       "<span class=\"lister-item-year text-muted unbold\">(1994)</span>\n",
       "</h3>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles= soup.find(\"h3\", class_=\"lister-item-header\")\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.The Shawshank Redemption(1994)',\n",
       " '2.The Godfather(1972)',\n",
       " '3.The Godfather: Part II(1974)',\n",
       " '4.The Dark Knight(2008)',\n",
       " '5.12 Angry Men(1957)',\n",
       " \"6.Schindler's List(1993)\",\n",
       " '7.The Lord of the Rings: The Return of the King(2003)',\n",
       " '8.Pulp Fiction(1994)',\n",
       " '9.Il buono, il brutto, il cattivo(1966)',\n",
       " '10.Fight Club(1999)',\n",
       " '11.Joker(2019)',\n",
       " '12.The Lord of the Rings: The Fellowship of the Ring(2001)',\n",
       " '13.Forrest Gump(1994)',\n",
       " '14.Inception(2010)',\n",
       " '15.Star Wars: Episode V - The Empire Strikes Back(1980)',\n",
       " '16.The Lord of the Rings: The Two Towers(2002)',\n",
       " '17.The Matrix(1999)',\n",
       " \"18.One Flew Over the Cuckoo's Nest(1975)\",\n",
       " '19.Goodfellas(1990)',\n",
       " '20.Shichinin no samurai(1954)',\n",
       " '21.Se7en(1995)',\n",
       " '22.Cidade de Deus(2002)',\n",
       " '23.La vita è bella(1997)',\n",
       " '24.The Silence of the Lambs(1991)',\n",
       " '25.Star Wars(1977)',\n",
       " \"26.It's a Wonderful Life(1946)\",\n",
       " '27.Saving Private Ryan(1998)',\n",
       " '28.Sen to Chihiro no kamikakushi(2001)',\n",
       " '29.The Green Mile(1999)',\n",
       " '30.Léon(1994)',\n",
       " '31.Seppuku(1962)',\n",
       " '32.Interstellar(2014)',\n",
       " '33.The Usual Suspects(1995)',\n",
       " '34.The Lion King(1994)',\n",
       " '35.American History X(1998)',\n",
       " '36.Back to the Future(1985)',\n",
       " '37.The Pianist(2002)',\n",
       " '38.Modern Times(1936)',\n",
       " '39.Terminator 2: Judgment Day(1991)',\n",
       " '40.The Intouchables(2011)',\n",
       " '41.Psycho(1960)',\n",
       " '42.Gladiator(2000)',\n",
       " '43.City Lights(1931)',\n",
       " '44.The Departed(2006)',\n",
       " '45.Whiplash(2014)',\n",
       " '46.Once Upon a Time in the West(1968)',\n",
       " '47.The Prestige(2006)',\n",
       " '48.Avengers: Endgame(2019)',\n",
       " '49.Casablanca(1942)',\n",
       " '50.Hotaru no haka(1988)',\n",
       " '51.Rear Window(1954)',\n",
       " '52.Nuovo Cinema Paradiso(1988)',\n",
       " '53.Alien(1979)',\n",
       " '54.Raiders of the Lost Ark(1981)',\n",
       " '55.Memento(2000)',\n",
       " '56.Apocalypse Now(1979)',\n",
       " '57.The Great Dictator(1940)',\n",
       " '58.The Lives of Others(2006)',\n",
       " '59.Avengers: Infinity War(2018)',\n",
       " '60.Django Unchained(2012)',\n",
       " '61.Spider-Man: Into the Spider-Verse(2018)',\n",
       " '62.The Shining(1980)',\n",
       " '63.Paths of Glory(1957)',\n",
       " '64.WALL·E(2008)',\n",
       " '65.Sunset Blvd.(1950)',\n",
       " '66.Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb(1964)',\n",
       " '67.Mononoke-hime(1997)',\n",
       " '68.Oldeuboi(2003)',\n",
       " '69.Witness for the Prosecution(1957)',\n",
       " '70.The Dark Knight Rises(2012)',\n",
       " '71.Once Upon a Time in America(1984)',\n",
       " '72.Gisaengchung(2019)',\n",
       " '73.Aliens(1986)',\n",
       " '74.American Beauty(1999)',\n",
       " '75.Coco(I) (2017)',\n",
       " '76.Kimi no na wa.(2016)',\n",
       " '77.Braveheart(1995)',\n",
       " '78.Das Boot(1981)',\n",
       " '79.3 Idiots(2009)',\n",
       " '80.Taare Zameen Par(2007)',\n",
       " '81.Star Wars: Episode VI - Return of the Jedi(1983)',\n",
       " '82.Toy Story(1995)',\n",
       " '83.Reservoir Dogs(1992)',\n",
       " '84.Amadeus(1984)',\n",
       " '85.Dangal(2016)',\n",
       " '86.Good Will Hunting(1997)',\n",
       " '87.Inglourious Basterds(2009)',\n",
       " '88.M - Eine Stadt sucht einen Mörder(1931)',\n",
       " '89.Requiem for a Dream(2000)',\n",
       " '90.2001: A Space Odyssey(1968)',\n",
       " '91.Vertigo(1958)',\n",
       " '92.Eternal Sunshine of the Spotless Mind(2004)',\n",
       " '93.Citizen Kane(1941)',\n",
       " '94.Full Metal Jacket(1987)',\n",
       " '95.Jagten(2012)',\n",
       " '96.North by Northwest(1959)',\n",
       " '97.A Clockwork Orange(1971)',\n",
       " '98.Snatch(2000)',\n",
       " \"99.Le fabuleux destin d'Amélie Poulain(2001)\",\n",
       " '100.The Kid(1921)']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping movie names\n",
    "movie_names=[]\n",
    "for i in soup.find_all('h3',class_='lister-item-header'):\n",
    "    movie_names.append(i.text.replace('\\n',\"\"))\n",
    "movie_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.The Shawshank Redemption',\n",
       " '2.The Godfather',\n",
       " '3.The Godfather: Part II',\n",
       " '4.The Dark Knight',\n",
       " '5.12 Angry Men',\n",
       " \"6.Schindler's List\",\n",
       " '7.The Lord of the Rings: The Return of the King',\n",
       " '8.Pulp Fiction',\n",
       " '9.Il buono, il brutto, il cattivo',\n",
       " '10.Fight Club',\n",
       " '11.Joker',\n",
       " '12.The Lord of the Rings: The Fellowship of the Ring',\n",
       " '13.Forrest Gump',\n",
       " '14.Inception',\n",
       " '15.Star Wars: Episode V - The Empire Strikes Back',\n",
       " '16.The Lord of the Rings: The Two Towers',\n",
       " '17.The Matrix',\n",
       " \"18.One Flew Over the Cuckoo's Nest\",\n",
       " '19.Goodfellas',\n",
       " '20.Shichinin no samurai',\n",
       " '21.Se7en',\n",
       " '22.Cidade de Deus',\n",
       " '23.La vita è bella',\n",
       " '24.The Silence of the Lambs',\n",
       " '25.Star Wars',\n",
       " \"26.It's a Wonderful Life\",\n",
       " '27.Saving Private Ryan',\n",
       " '28.Sen to Chihiro no kamikakushi',\n",
       " '29.The Green Mile',\n",
       " '30.Léon',\n",
       " '31.Seppuku',\n",
       " '32.Interstellar',\n",
       " '33.The Usual Suspects',\n",
       " '34.The Lion King',\n",
       " '35.American History X',\n",
       " '36.Back to the Future',\n",
       " '37.The Pianist',\n",
       " '38.Modern Times',\n",
       " '39.Terminator 2: Judgment Day',\n",
       " '40.The Intouchables',\n",
       " '41.Psycho',\n",
       " '42.Gladiator',\n",
       " '43.City Lights',\n",
       " '44.The Departed',\n",
       " '45.Whiplash',\n",
       " '46.Once Upon a Time in the West',\n",
       " '47.The Prestige',\n",
       " '48.Avengers: Endgame',\n",
       " '49.Casablanca',\n",
       " '50.Hotaru no haka',\n",
       " '51.Rear Window',\n",
       " '52.Nuovo Cinema Paradiso',\n",
       " '53.Alien',\n",
       " '54.Raiders of the Lost Ark',\n",
       " '55.Memento',\n",
       " '56.Apocalypse Now',\n",
       " '57.The Great Dictator',\n",
       " '58.The Lives of Others',\n",
       " '59.Avengers: Infinity War',\n",
       " '60.Django Unchained',\n",
       " '61.Spider-Man: Into the Spider-Verse',\n",
       " '62.The Shining',\n",
       " '63.Paths of Glory',\n",
       " '64.WALL·E',\n",
       " '65.Sunset Blvd.',\n",
       " '66.Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb',\n",
       " '67.Mononoke-hime',\n",
       " '68.Oldeuboi',\n",
       " '69.Witness for the Prosecution',\n",
       " '70.The Dark Knight Rises',\n",
       " '71.Once Upon a Time in America',\n",
       " '72.Gisaengchung',\n",
       " '73.Aliens',\n",
       " '74.American Beauty',\n",
       " '75.Coco(I) ',\n",
       " '76.Kimi no na wa.',\n",
       " '77.Braveheart',\n",
       " '78.Das Boot',\n",
       " '79.3 Idiots',\n",
       " '80.Taare Zameen Par',\n",
       " '81.Star Wars: Episode VI - Return of the Jedi',\n",
       " '82.Toy Story',\n",
       " '83.Reservoir Dogs',\n",
       " '84.Amadeus',\n",
       " '85.Dangal',\n",
       " '86.Good Will Hunting',\n",
       " '87.Inglourious Basterds',\n",
       " '88.M - Eine Stadt sucht einen Mörder',\n",
       " '89.Requiem for a Dream',\n",
       " '90.2001: A Space Odyssey',\n",
       " '91.Vertigo',\n",
       " '92.Eternal Sunshine of the Spotless Mind',\n",
       " '93.Citizen Kane',\n",
       " '94.Full Metal Jacket',\n",
       " '95.Jagten',\n",
       " '96.North by Northwest',\n",
       " '97.A Clockwork Orange',\n",
       " '98.Snatch',\n",
       " \"99.Le fabuleux destin d'Amélie Poulain\",\n",
       " '100.The Kid']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing year from last\n",
    "movie_names = [x[:-6] for x in movie_names]\n",
    "movie_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"lister-item-year text-muted unbold\">(1994)</span>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year= soup.find('span', class_=\"lister-item-year text-muted unbold\")\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(1974)',\n",
       " '(2008)',\n",
       " '(1957)',\n",
       " '(1993)',\n",
       " '(2003)',\n",
       " '(1994)',\n",
       " '(1966)',\n",
       " '(1999)',\n",
       " '(2019)',\n",
       " '(2001)',\n",
       " '(1994)',\n",
       " '(2010)',\n",
       " '(1980)',\n",
       " '(2002)',\n",
       " '(1999)',\n",
       " '(1975)',\n",
       " '(1990)',\n",
       " '(1954)',\n",
       " '(1995)',\n",
       " '(2002)',\n",
       " '(1997)',\n",
       " '(1991)',\n",
       " '(1977)',\n",
       " '(1946)',\n",
       " '(1998)',\n",
       " '(2001)',\n",
       " '(1999)',\n",
       " '(1994)',\n",
       " '(1962)',\n",
       " '(2014)',\n",
       " '(1995)',\n",
       " '(1994)',\n",
       " '(1998)',\n",
       " '(1985)',\n",
       " '(2002)',\n",
       " '(1936)',\n",
       " '(1991)',\n",
       " '(2011)',\n",
       " '(1960)',\n",
       " '(2000)',\n",
       " '(1931)',\n",
       " '(2006)',\n",
       " '(2014)',\n",
       " '(1968)',\n",
       " '(2006)',\n",
       " '(2019)',\n",
       " '(1942)',\n",
       " '(1988)',\n",
       " '(1954)',\n",
       " '(1988)',\n",
       " '(1979)',\n",
       " '(1981)',\n",
       " '(2000)',\n",
       " '(1979)',\n",
       " '(1940)',\n",
       " '(2006)',\n",
       " '(2018)',\n",
       " '(2012)',\n",
       " '(2018)',\n",
       " '(1980)',\n",
       " '(1957)',\n",
       " '(2008)',\n",
       " '(1950)',\n",
       " '(1964)',\n",
       " '(1997)',\n",
       " '(2003)',\n",
       " '(1957)',\n",
       " '(2012)',\n",
       " '(1984)',\n",
       " '(2019)',\n",
       " '(1986)',\n",
       " '(1999)',\n",
       " '(I) (2017)',\n",
       " '(2016)',\n",
       " '(1995)',\n",
       " '(1981)',\n",
       " '(2009)',\n",
       " '(2007)',\n",
       " '(1983)',\n",
       " '(1995)',\n",
       " '(1992)',\n",
       " '(1984)',\n",
       " '(2016)',\n",
       " '(1997)',\n",
       " '(2009)',\n",
       " '(1931)',\n",
       " '(2000)',\n",
       " '(1968)',\n",
       " '(1958)',\n",
       " '(2004)',\n",
       " '(1941)',\n",
       " '(1987)',\n",
       " '(2012)',\n",
       " '(1959)',\n",
       " '(1971)',\n",
       " '(2000)',\n",
       " '(2001)',\n",
       " '(1921)']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping years\n",
    "year= []\n",
    "for i in soup.find_all('span' ,class_=\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(1974)',\n",
       " '(2008)',\n",
       " '(1957)',\n",
       " '(1993)',\n",
       " '(2003)',\n",
       " '(1994)',\n",
       " '(1966)',\n",
       " '(1999)',\n",
       " '(2019)',\n",
       " '(2001)',\n",
       " '(1994)',\n",
       " '(2010)',\n",
       " '(1980)',\n",
       " '(2002)',\n",
       " '(1999)',\n",
       " '(1975)',\n",
       " '(1990)',\n",
       " '(1954)',\n",
       " '(1995)',\n",
       " '(2002)',\n",
       " '(1997)',\n",
       " '(1991)',\n",
       " '(1977)',\n",
       " '(1946)',\n",
       " '(1998)',\n",
       " '(2001)',\n",
       " '(1999)',\n",
       " '(1994)',\n",
       " '(1962)',\n",
       " '(2014)',\n",
       " '(1995)',\n",
       " '(1994)',\n",
       " '(1998)',\n",
       " '(1985)',\n",
       " '(2002)',\n",
       " '(1936)',\n",
       " '(1991)',\n",
       " '(2011)',\n",
       " '(1960)',\n",
       " '(2000)',\n",
       " '(1931)',\n",
       " '(2006)',\n",
       " '(2014)',\n",
       " '(1968)',\n",
       " '(2006)',\n",
       " '(2019)',\n",
       " '(1942)',\n",
       " '(1988)',\n",
       " '(1954)',\n",
       " '(1988)',\n",
       " '(1979)',\n",
       " '(1981)',\n",
       " '(2000)',\n",
       " '(1979)',\n",
       " '(1940)',\n",
       " '(2006)',\n",
       " '(2018)',\n",
       " '(2012)',\n",
       " '(2018)',\n",
       " '(1980)',\n",
       " '(1957)',\n",
       " '(2008)',\n",
       " '(1950)',\n",
       " '(1964)',\n",
       " '(1997)',\n",
       " '(2003)',\n",
       " '(1957)',\n",
       " '(2012)',\n",
       " '(1984)',\n",
       " '(2019)',\n",
       " '(1986)',\n",
       " '(1999)',\n",
       " ' (2017)',\n",
       " '(2016)',\n",
       " '(1995)',\n",
       " '(1981)',\n",
       " '(2009)',\n",
       " '(2007)',\n",
       " '(1983)',\n",
       " '(1995)',\n",
       " '(1992)',\n",
       " '(1984)',\n",
       " '(2016)',\n",
       " '(1997)',\n",
       " '(2009)',\n",
       " '(1931)',\n",
       " '(2000)',\n",
       " '(1968)',\n",
       " '(1958)',\n",
       " '(2004)',\n",
       " '(1941)',\n",
       " '(1987)',\n",
       " '(2012)',\n",
       " '(1959)',\n",
       " '(1971)',\n",
       " '(2000)',\n",
       " '(2001)',\n",
       " '(1921)']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing (I)\n",
    "years=[s.replace(\"(I)\", \"\") for s in year]\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"ipl-rating-star small\">\n",
       "<span class=\"ipl-rating-star__star\">\n",
       "<svg class=\"ipl-icon ipl-star-icon\" fill=\"#000000\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M0 0h24v24H0z\" fill=\"none\"></path>\n",
       "<path d=\"M12 17.27L18.18 21l-1.64-7.03L22 9.24l-7.19-.61L12 2 9.19 8.63 2 9.24l5.46 4.73L5.82 21z\"></path>\n",
       "<path d=\"M0 0h24v24H0z\" fill=\"none\"></path>\n",
       "</svg>\n",
       "</span>\n",
       "<span class=\"ipl-rating-star__rating\">9.3</span>\n",
       "</div>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating= soup.find('div' ,class_=\"ipl-rating-star small\")\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '9.2',\n",
       " '9',\n",
       " '9',\n",
       " '9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.4',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.3',\n",
       " '8.3']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping ratings\n",
    "rating= []\n",
    "for i in soup.find_all('div', class_=\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.replace('\\n',\"\"))\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "# Finding length\n",
    "print(len(movie_names), len(years), len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.The Godfather: Part II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.12 Angry Men</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.North by Northwest</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.A Clockwork Orange</td>\n",
       "      <td>(1971)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.Snatch</td>\n",
       "      <td>(2000)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.The Kid</td>\n",
       "      <td>(1921)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Movie Name Year of Release Rating\n",
       "0               1.The Shawshank Redemption          (1994)    9.3\n",
       "1                          2.The Godfather          (1972)    9.2\n",
       "2                 3.The Godfather: Part II          (1974)      9\n",
       "3                        4.The Dark Knight          (2008)      9\n",
       "4                           5.12 Angry Men          (1957)      9\n",
       "..                                     ...             ...    ...\n",
       "95                   96.North by Northwest          (1959)    8.3\n",
       "96                   97.A Clockwork Orange          (1971)    8.3\n",
       "97                               98.Snatch          (2000)    8.2\n",
       "98  99.Le fabuleux destin d'Amélie Poulain          (2001)    8.3\n",
       "99                             100.The Kid          (1921)    8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "imdb_top100_movies=pd.DataFrame({'Movie Name':movie_names,'Year of Release':years, 'Rating':rating})\n",
    "imdb_top100_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- IMDB’s Top rated 100 Indian Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requests to a server\n",
    "page= requests.get('https://www.imdb.com/list/ls009997493/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3 class=\"lister-item-header\">\n",
       "<span class=\"lister-item-index unbold text-primary\">1.</span>\n",
       "<a href=\"/title/tt0111161/\">The Shawshank Redemption</a>\n",
       "<span class=\"lister-item-year text-muted unbold\">(1994)</span>\n",
       "</h3>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name= soup.find('h3', class_='lister-item-header')\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.The Shawshank Redemption(1994)',\n",
       " '2.The Godfather(1972)',\n",
       " '3.The Godfather: Part II(1974)',\n",
       " '4.The Dark Knight(2008)',\n",
       " '5.12 Angry Men(1957)',\n",
       " \"6.Schindler's List(1993)\",\n",
       " '7.The Lord of the Rings: The Return of the King(2003)',\n",
       " '8.Pulp Fiction(1994)',\n",
       " '9.Il buono, il brutto, il cattivo(1966)',\n",
       " '10.Fight Club(1999)',\n",
       " '11.Joker(2019)',\n",
       " '12.The Lord of the Rings: The Fellowship of the Ring(2001)',\n",
       " '13.Forrest Gump(1994)',\n",
       " '14.Inception(2010)',\n",
       " '15.Star Wars: Episode V - The Empire Strikes Back(1980)',\n",
       " '16.The Lord of the Rings: The Two Towers(2002)',\n",
       " '17.The Matrix(1999)',\n",
       " \"18.One Flew Over the Cuckoo's Nest(1975)\",\n",
       " '19.Goodfellas(1990)',\n",
       " '20.Shichinin no samurai(1954)',\n",
       " '21.Se7en(1995)',\n",
       " '22.Cidade de Deus(2002)',\n",
       " '23.La vita è bella(1997)',\n",
       " '24.The Silence of the Lambs(1991)',\n",
       " '25.Star Wars(1977)',\n",
       " \"26.It's a Wonderful Life(1946)\",\n",
       " '27.Saving Private Ryan(1998)',\n",
       " '28.Sen to Chihiro no kamikakushi(2001)',\n",
       " '29.The Green Mile(1999)',\n",
       " '30.Léon(1994)',\n",
       " '31.Seppuku(1962)',\n",
       " '32.Interstellar(2014)',\n",
       " '33.The Usual Suspects(1995)',\n",
       " '34.The Lion King(1994)',\n",
       " '35.American History X(1998)',\n",
       " '36.Back to the Future(1985)',\n",
       " '37.The Pianist(2002)',\n",
       " '38.Modern Times(1936)',\n",
       " '39.Terminator 2: Judgment Day(1991)',\n",
       " '40.The Intouchables(2011)',\n",
       " '41.Psycho(1960)',\n",
       " '42.Gladiator(2000)',\n",
       " '43.City Lights(1931)',\n",
       " '44.The Departed(2006)',\n",
       " '45.Whiplash(2014)',\n",
       " '46.Once Upon a Time in the West(1968)',\n",
       " '47.The Prestige(2006)',\n",
       " '48.Avengers: Endgame(2019)',\n",
       " '49.Casablanca(1942)',\n",
       " '50.Hotaru no haka(1988)',\n",
       " '51.Rear Window(1954)',\n",
       " '52.Nuovo Cinema Paradiso(1988)',\n",
       " '53.Alien(1979)',\n",
       " '54.Raiders of the Lost Ark(1981)',\n",
       " '55.Memento(2000)',\n",
       " '56.Apocalypse Now(1979)',\n",
       " '57.The Great Dictator(1940)',\n",
       " '58.The Lives of Others(2006)',\n",
       " '59.Avengers: Infinity War(2018)',\n",
       " '60.Django Unchained(2012)',\n",
       " '61.Spider-Man: Into the Spider-Verse(2018)',\n",
       " '62.The Shining(1980)',\n",
       " '63.Paths of Glory(1957)',\n",
       " '64.WALL·E(2008)',\n",
       " '65.Sunset Blvd.(1950)',\n",
       " '66.Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb(1964)',\n",
       " '67.Mononoke-hime(1997)',\n",
       " '68.Oldeuboi(2003)',\n",
       " '69.Witness for the Prosecution(1957)',\n",
       " '70.The Dark Knight Rises(2012)',\n",
       " '71.Once Upon a Time in America(1984)',\n",
       " '72.Gisaengchung(2019)',\n",
       " '73.Aliens(1986)',\n",
       " '74.American Beauty(1999)',\n",
       " '75.Coco(I) (2017)',\n",
       " '76.Kimi no na wa.(2016)',\n",
       " '77.Braveheart(1995)',\n",
       " '78.Das Boot(1981)',\n",
       " '79.3 Idiots(2009)',\n",
       " '80.Taare Zameen Par(2007)',\n",
       " '81.Star Wars: Episode VI - Return of the Jedi(1983)',\n",
       " '82.Toy Story(1995)',\n",
       " '83.Reservoir Dogs(1992)',\n",
       " '84.Amadeus(1984)',\n",
       " '85.Dangal(2016)',\n",
       " '86.Good Will Hunting(1997)',\n",
       " '87.Inglourious Basterds(2009)',\n",
       " '88.M - Eine Stadt sucht einen Mörder(1931)',\n",
       " '89.Requiem for a Dream(2000)',\n",
       " '90.2001: A Space Odyssey(1968)',\n",
       " '91.Vertigo(1958)',\n",
       " '92.Eternal Sunshine of the Spotless Mind(2004)',\n",
       " '93.Citizen Kane(1941)',\n",
       " '94.Full Metal Jacket(1987)',\n",
       " '95.Jagten(2012)',\n",
       " '96.North by Northwest(1959)',\n",
       " '97.A Clockwork Orange(1971)',\n",
       " '98.Snatch(2000)',\n",
       " \"99.Le fabuleux destin d'Amélie Poulain(2001)\",\n",
       " '100.The Kid(1921)']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping movie's names\n",
    "names= []\n",
    "for i in soup.find_all('h3', class_='lister-item-header'):\n",
    "    names.append(i.text.replace('\\n',\"\"))\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.The Shawshank Redemption',\n",
       " '2.The Godfather',\n",
       " '3.The Godfather: Part II',\n",
       " '4.The Dark Knight',\n",
       " '5.12 Angry Men',\n",
       " \"6.Schindler's List\",\n",
       " '7.The Lord of the Rings: The Return of the King',\n",
       " '8.Pulp Fiction',\n",
       " '9.Il buono, il brutto, il cattivo',\n",
       " '10.Fight Club',\n",
       " '11.Joker',\n",
       " '12.The Lord of the Rings: The Fellowship of the Ring',\n",
       " '13.Forrest Gump',\n",
       " '14.Inception',\n",
       " '15.Star Wars: Episode V - The Empire Strikes Back',\n",
       " '16.The Lord of the Rings: The Two Towers',\n",
       " '17.The Matrix',\n",
       " \"18.One Flew Over the Cuckoo's Nest\",\n",
       " '19.Goodfellas',\n",
       " '20.Shichinin no samurai',\n",
       " '21.Se7en',\n",
       " '22.Cidade de Deus',\n",
       " '23.La vita è bella',\n",
       " '24.The Silence of the Lambs',\n",
       " '25.Star Wars',\n",
       " \"26.It's a Wonderful Life\",\n",
       " '27.Saving Private Ryan',\n",
       " '28.Sen to Chihiro no kamikakushi',\n",
       " '29.The Green Mile',\n",
       " '30.Léon',\n",
       " '31.Seppuku',\n",
       " '32.Interstellar',\n",
       " '33.The Usual Suspects',\n",
       " '34.The Lion King',\n",
       " '35.American History X',\n",
       " '36.Back to the Future',\n",
       " '37.The Pianist',\n",
       " '38.Modern Times',\n",
       " '39.Terminator 2: Judgment Day',\n",
       " '40.The Intouchables',\n",
       " '41.Psycho',\n",
       " '42.Gladiator',\n",
       " '43.City Lights',\n",
       " '44.The Departed',\n",
       " '45.Whiplash',\n",
       " '46.Once Upon a Time in the West',\n",
       " '47.The Prestige',\n",
       " '48.Avengers: Endgame',\n",
       " '49.Casablanca',\n",
       " '50.Hotaru no haka',\n",
       " '51.Rear Window',\n",
       " '52.Nuovo Cinema Paradiso',\n",
       " '53.Alien',\n",
       " '54.Raiders of the Lost Ark',\n",
       " '55.Memento',\n",
       " '56.Apocalypse Now',\n",
       " '57.The Great Dictator',\n",
       " '58.The Lives of Others',\n",
       " '59.Avengers: Infinity War',\n",
       " '60.Django Unchained',\n",
       " '61.Spider-Man: Into the Spider-Verse',\n",
       " '62.The Shining',\n",
       " '63.Paths of Glory',\n",
       " '64.WALL·E',\n",
       " '65.Sunset Blvd.',\n",
       " '66.Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb',\n",
       " '67.Mononoke-hime',\n",
       " '68.Oldeuboi',\n",
       " '69.Witness for the Prosecution',\n",
       " '70.The Dark Knight Rises',\n",
       " '71.Once Upon a Time in America',\n",
       " '72.Gisaengchung',\n",
       " '73.Aliens',\n",
       " '74.American Beauty',\n",
       " '75.Coco(I) ',\n",
       " '76.Kimi no na wa.',\n",
       " '77.Braveheart',\n",
       " '78.Das Boot',\n",
       " '79.3 Idiots',\n",
       " '80.Taare Zameen Par',\n",
       " '81.Star Wars: Episode VI - Return of the Jedi',\n",
       " '82.Toy Story',\n",
       " '83.Reservoir Dogs',\n",
       " '84.Amadeus',\n",
       " '85.Dangal',\n",
       " '86.Good Will Hunting',\n",
       " '87.Inglourious Basterds',\n",
       " '88.M - Eine Stadt sucht einen Mörder',\n",
       " '89.Requiem for a Dream',\n",
       " '90.2001: A Space Odyssey',\n",
       " '91.Vertigo',\n",
       " '92.Eternal Sunshine of the Spotless Mind',\n",
       " '93.Citizen Kane',\n",
       " '94.Full Metal Jacket',\n",
       " '95.Jagten',\n",
       " '96.North by Northwest',\n",
       " '97.A Clockwork Orange',\n",
       " '98.Snatch',\n",
       " \"99.Le fabuleux destin d'Amélie Poulain\",\n",
       " '100.The Kid']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing years\n",
    "names = [x[:-6] for x in names]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"lister-item-year text-muted unbold\">(1994)</span>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping movie year\n",
    "year= soup.find('span', class_=\"lister-item-year text-muted unbold\")\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(1974)',\n",
       " '(2008)',\n",
       " '(1957)',\n",
       " '(1993)',\n",
       " '(2003)',\n",
       " '(1994)',\n",
       " '(1966)',\n",
       " '(1999)',\n",
       " '(2019)',\n",
       " '(2001)',\n",
       " '(1994)',\n",
       " '(2010)',\n",
       " '(1980)',\n",
       " '(2002)',\n",
       " '(1999)',\n",
       " '(1975)',\n",
       " '(1990)',\n",
       " '(1954)',\n",
       " '(1995)',\n",
       " '(2002)',\n",
       " '(1997)',\n",
       " '(1991)',\n",
       " '(1977)',\n",
       " '(1946)',\n",
       " '(1998)',\n",
       " '(2001)',\n",
       " '(1999)',\n",
       " '(1994)',\n",
       " '(1962)',\n",
       " '(2014)',\n",
       " '(1995)',\n",
       " '(1994)',\n",
       " '(1998)',\n",
       " '(1985)',\n",
       " '(2002)',\n",
       " '(1936)',\n",
       " '(1991)',\n",
       " '(2011)',\n",
       " '(1960)',\n",
       " '(2000)',\n",
       " '(1931)',\n",
       " '(2006)',\n",
       " '(2014)',\n",
       " '(1968)',\n",
       " '(2006)',\n",
       " '(2019)',\n",
       " '(1942)',\n",
       " '(1988)',\n",
       " '(1954)',\n",
       " '(1988)',\n",
       " '(1979)',\n",
       " '(1981)',\n",
       " '(2000)',\n",
       " '(1979)',\n",
       " '(1940)',\n",
       " '(2006)',\n",
       " '(2018)',\n",
       " '(2012)',\n",
       " '(2018)',\n",
       " '(1980)',\n",
       " '(1957)',\n",
       " '(2008)',\n",
       " '(1950)',\n",
       " '(1964)',\n",
       " '(1997)',\n",
       " '(2003)',\n",
       " '(1957)',\n",
       " '(2012)',\n",
       " '(1984)',\n",
       " '(2019)',\n",
       " '(1986)',\n",
       " '(1999)',\n",
       " '(I) (2017)',\n",
       " '(2016)',\n",
       " '(1995)',\n",
       " '(1981)',\n",
       " '(2009)',\n",
       " '(2007)',\n",
       " '(1983)',\n",
       " '(1995)',\n",
       " '(1992)',\n",
       " '(1984)',\n",
       " '(2016)',\n",
       " '(1997)',\n",
       " '(2009)',\n",
       " '(1931)',\n",
       " '(2000)',\n",
       " '(1968)',\n",
       " '(1958)',\n",
       " '(2004)',\n",
       " '(1941)',\n",
       " '(1987)',\n",
       " '(2012)',\n",
       " '(1959)',\n",
       " '(1971)',\n",
       " '(2000)',\n",
       " '(2001)',\n",
       " '(1921)']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years= []\n",
    "for i in soup.find_all('span' ,class_=\"lister-item-year text-muted unbold\"):\n",
    "    years.append(i.text)\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(1974)',\n",
       " '(2008)',\n",
       " '(1957)',\n",
       " '(1993)',\n",
       " '(2003)',\n",
       " '(1994)',\n",
       " '(1966)',\n",
       " '(1999)',\n",
       " '(2019)',\n",
       " '(2001)',\n",
       " '(1994)',\n",
       " '(2010)',\n",
       " '(1980)',\n",
       " '(2002)',\n",
       " '(1999)',\n",
       " '(1975)',\n",
       " '(1990)',\n",
       " '(1954)',\n",
       " '(1995)',\n",
       " '(2002)',\n",
       " '(1997)',\n",
       " '(1991)',\n",
       " '(1977)',\n",
       " '(1946)',\n",
       " '(1998)',\n",
       " '(2001)',\n",
       " '(1999)',\n",
       " '(1994)',\n",
       " '(1962)',\n",
       " '(2014)',\n",
       " '(1995)',\n",
       " '(1994)',\n",
       " '(1998)',\n",
       " '(1985)',\n",
       " '(2002)',\n",
       " '(1936)',\n",
       " '(1991)',\n",
       " '(2011)',\n",
       " '(1960)',\n",
       " '(2000)',\n",
       " '(1931)',\n",
       " '(2006)',\n",
       " '(2014)',\n",
       " '(1968)',\n",
       " '(2006)',\n",
       " '(2019)',\n",
       " '(1942)',\n",
       " '(1988)',\n",
       " '(1954)',\n",
       " '(1988)',\n",
       " '(1979)',\n",
       " '(1981)',\n",
       " '(2000)',\n",
       " '(1979)',\n",
       " '(1940)',\n",
       " '(2006)',\n",
       " '(2018)',\n",
       " '(2012)',\n",
       " '(2018)',\n",
       " '(1980)',\n",
       " '(1957)',\n",
       " '(2008)',\n",
       " '(1950)',\n",
       " '(1964)',\n",
       " '(1997)',\n",
       " '(2003)',\n",
       " '(1957)',\n",
       " '(2012)',\n",
       " '(1984)',\n",
       " '(2019)',\n",
       " '(1986)',\n",
       " '(1999)',\n",
       " ' (2017)',\n",
       " '(2016)',\n",
       " '(1995)',\n",
       " '(1981)',\n",
       " '(2009)',\n",
       " '(2007)',\n",
       " '(1983)',\n",
       " '(1995)',\n",
       " '(1992)',\n",
       " '(1984)',\n",
       " '(2016)',\n",
       " '(1997)',\n",
       " '(2009)',\n",
       " '(1931)',\n",
       " '(2000)',\n",
       " '(1968)',\n",
       " '(1958)',\n",
       " '(2004)',\n",
       " '(1941)',\n",
       " '(1987)',\n",
       " '(2012)',\n",
       " '(1959)',\n",
       " '(1971)',\n",
       " '(2000)',\n",
       " '(2001)',\n",
       " '(1921)']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing(I)\n",
    "years=[s.replace(\"(I)\", \"\") for s in years]\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"ipl-rating-star small\">\n",
       "<span class=\"ipl-rating-star__star\">\n",
       "<svg class=\"ipl-icon ipl-star-icon\" fill=\"#000000\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M0 0h24v24H0z\" fill=\"none\"></path>\n",
       "<path d=\"M12 17.27L18.18 21l-1.64-7.03L22 9.24l-7.19-.61L12 2 9.19 8.63 2 9.24l5.46 4.73L5.82 21z\"></path>\n",
       "<path d=\"M0 0h24v24H0z\" fill=\"none\"></path>\n",
       "</svg>\n",
       "</span>\n",
       "<span class=\"ipl-rating-star__rating\">9.3</span>\n",
       "</div>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating= soup.find('div' ,class_=\"ipl-rating-star small\")\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '9.2',\n",
       " '9',\n",
       " '9',\n",
       " '9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.4',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.3',\n",
       " '8.3']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping ratings\n",
    "rating= []\n",
    "for i in soup.find_all('div', class_=\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.replace('\\n',\"\"))\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "# Find length \n",
    "print(len(names), len(years), len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Year of release</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.The Godfather: Part II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.12 Angry Men</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.North by Northwest</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.A Clockwork Orange</td>\n",
       "      <td>(1971)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.Snatch</td>\n",
       "      <td>(2000)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.The Kid</td>\n",
       "      <td>(1921)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Movie Name Year of release Rating\n",
       "0               1.The Shawshank Redemption          (1994)    9.3\n",
       "1                          2.The Godfather          (1972)    9.2\n",
       "2                 3.The Godfather: Part II          (1974)      9\n",
       "3                        4.The Dark Knight          (2008)      9\n",
       "4                           5.12 Angry Men          (1957)      9\n",
       "..                                     ...             ...    ...\n",
       "95                   96.North by Northwest          (1959)    8.3\n",
       "96                   97.A Clockwork Orange          (1971)    8.3\n",
       "97                               98.Snatch          (2000)    8.2\n",
       "98  99.Le fabuleux destin d'Amélie Poulain          (2001)    8.3\n",
       "99                             100.The Kid          (1921)    8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "imdb_top100_indianmovies= pd.DataFrame({'Movie Name':names, 'Year of release':years, 'Rating':rating})\n",
    "imdb_top100_indianmovies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- meesho.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requests to a server\n",
    "page= requests.get('https://meesho.com/bags-ladies/pl/p7vbp')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content\n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\" color=\"greyT2\" font-size=\"16px\" font-weight=\"book\">Elite Fancy Women Handbags</p>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping product name\n",
    "product_name= soup.find('p', class_=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\")\n",
    "product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elite Fancy Women Handbags'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_name.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elite Fancy Women Handbags',\n",
       " 'Moon Mart Latest girls and kids Handbag',\n",
       " 'Ravishing Attractive Women Handbags',\n",
       " 'Ravishing Fancy Women Handbags',\n",
       " 'Elite Alluring Women Handbags',\n",
       " 'jeanspatterncaplady Handbags ',\n",
       " 'Jute Bags',\n",
       " 'Benicia Giraffe Print Poly Canvas Tote Bag with Zipper Closure Handbags ',\n",
       " 'Hend bags ',\n",
       " 'Handbags',\n",
       " 'SHA-LUXE Handbag',\n",
       " 'jeanspatternhairlady',\n",
       " 'Voguish Attractive Women Handbags',\n",
       " 'Elite Fancy Women Handbags',\n",
       " 'ladies handbags',\n",
       " 'Voguish Stylish Women Handbags',\n",
       " 'Women PINK  Shoulder Bag - Extra Spacious',\n",
       " 'canvasgreenleafy',\n",
       " 'Classic Stylish Women Handbags',\n",
       " 'jutefloralbag']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple product names \n",
    "products_names=[]\n",
    "for i in soup.find_all('p', class_=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\"):\n",
    "    products_names.append(i.text)\n",
    "products_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h5 class=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\" color=\"greyBase\" font-size=\"24px\" font-weight=\"bold\">₹<!-- -->103</h5>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping product price\n",
    "price= soup.find('h5',  class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\")\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'₹103'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹103',\n",
       " '₹215',\n",
       " '₹383',\n",
       " '₹7',\n",
       " '₹383',\n",
       " '₹105',\n",
       " '₹434',\n",
       " '₹200',\n",
       " '₹285',\n",
       " '₹100',\n",
       " '₹305',\n",
       " '₹105',\n",
       " '₹383',\n",
       " '₹323',\n",
       " '₹245',\n",
       " '₹12',\n",
       " '₹199',\n",
       " '₹105',\n",
       " '₹9',\n",
       " '₹103']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple product price\n",
    "price= []\n",
    "for i in soup.find_all('h5',  class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\"):\n",
    "    price.append(i.text)\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"Text__StyledText-sc-oo0kvp-0 lnonyH\" color=\"greenBase\" font-size=\"16px\" font-weight=\"demi\">30<!-- -->% off</span>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping discount\n",
    "discount= soup.find('span', class_=\"Text__StyledText-sc-oo0kvp-0 lnonyH\")\n",
    "discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30% off'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30% off',\n",
       " '30% off',\n",
       " '21% off',\n",
       " '30% off',\n",
       " '21% off',\n",
       " '30% off',\n",
       " '19% off',\n",
       " '30% off',\n",
       " '26% off',\n",
       " '30% off',\n",
       " '25% off',\n",
       " '30% off',\n",
       " '21% off',\n",
       " '24% off',\n",
       " '29% off',\n",
       " '29% off',\n",
       " '30% off',\n",
       " '30% off',\n",
       " '25% off',\n",
       " '30% off']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple discounts\n",
    "discounts= []\n",
    "for i in soup.find_all('span', class_=\"Text__StyledText-sc-oo0kvp-0 lnonyH\"):\n",
    "    discounts.append(i.text)\n",
    "discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "# Finding length\n",
    "print(len(price), len(discounts), len(products_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elite Fancy Women Handbags</td>\n",
       "      <td>₹103</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moon Mart Latest girls and kids Handbag</td>\n",
       "      <td>₹215</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ravishing Attractive Women Handbags</td>\n",
       "      <td>₹383</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ravishing Fancy Women Handbags</td>\n",
       "      <td>₹7</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elite Alluring Women Handbags</td>\n",
       "      <td>₹383</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jeanspatterncaplady Handbags</td>\n",
       "      <td>₹105</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jute Bags</td>\n",
       "      <td>₹434</td>\n",
       "      <td>19% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Benicia Giraffe Print Poly Canvas Tote Bag wit...</td>\n",
       "      <td>₹200</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hend bags</td>\n",
       "      <td>₹285</td>\n",
       "      <td>26% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Handbags</td>\n",
       "      <td>₹100</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SHA-LUXE Handbag</td>\n",
       "      <td>₹305</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jeanspatternhairlady</td>\n",
       "      <td>₹105</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Voguish Attractive Women Handbags</td>\n",
       "      <td>₹383</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Elite Fancy Women Handbags</td>\n",
       "      <td>₹323</td>\n",
       "      <td>24% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ladies handbags</td>\n",
       "      <td>₹245</td>\n",
       "      <td>29% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Voguish Stylish Women Handbags</td>\n",
       "      <td>₹12</td>\n",
       "      <td>29% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Women PINK  Shoulder Bag - Extra Spacious</td>\n",
       "      <td>₹199</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>canvasgreenleafy</td>\n",
       "      <td>₹105</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Classic Stylish Women Handbags</td>\n",
       "      <td>₹9</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jutefloralbag</td>\n",
       "      <td>₹103</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Product Name Price Discount\n",
       "0                          Elite Fancy Women Handbags  ₹103  30% off\n",
       "1             Moon Mart Latest girls and kids Handbag  ₹215  30% off\n",
       "2                 Ravishing Attractive Women Handbags  ₹383  21% off\n",
       "3                      Ravishing Fancy Women Handbags    ₹7  30% off\n",
       "4                       Elite Alluring Women Handbags  ₹383  21% off\n",
       "5                       jeanspatterncaplady Handbags   ₹105  30% off\n",
       "6                                           Jute Bags  ₹434  19% off\n",
       "7   Benicia Giraffe Print Poly Canvas Tote Bag wit...  ₹200  30% off\n",
       "8                                          Hend bags   ₹285  26% off\n",
       "9                                            Handbags  ₹100  30% off\n",
       "10                                   SHA-LUXE Handbag  ₹305  25% off\n",
       "11                               jeanspatternhairlady  ₹105  30% off\n",
       "12                  Voguish Attractive Women Handbags  ₹383  21% off\n",
       "13                         Elite Fancy Women Handbags  ₹323  24% off\n",
       "14                                    ladies handbags  ₹245  29% off\n",
       "15                     Voguish Stylish Women Handbags   ₹12  29% off\n",
       "16          Women PINK  Shoulder Bag - Extra Spacious  ₹199  30% off\n",
       "17                                   canvasgreenleafy  ₹105  30% off\n",
       "18                     Classic Stylish Women Handbags    ₹9  25% off\n",
       "19                                      jutefloralbag  ₹103  30% off"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "ladies_bags= pd.DataFrame({'Product Name': products_names, 'Price':price, 'Discount': discounts})\n",
    "ladies_bags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- ICC Men Cricket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Top 10 ODI Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requests to a server\n",
    "page= requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page Content\n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"u-hide-phablet\">New Zealand</span>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team= soup.find('span', class_= \"u-hide-phablet\")\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Zealand',\n",
       " 'England',\n",
       " 'Australia',\n",
       " 'India',\n",
       " 'South Africa',\n",
       " 'Pakistan',\n",
       " 'Bangladesh',\n",
       " 'West Indies',\n",
       " 'Sri Lanka',\n",
       " 'Afghanistan',\n",
       " 'Netherlands',\n",
       " 'Ireland',\n",
       " 'Scotland',\n",
       " 'Zimbabwe',\n",
       " 'Oman',\n",
       " 'Nepal',\n",
       " 'UAE',\n",
       " 'United States',\n",
       " 'Namibia',\n",
       " 'Papua New Guinea',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Teams\n",
    "teams= []\n",
    "for i in soup.find_all('span',class_= \"u-hide-phablet\"):\n",
    "    teams.append(i.text)\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Zealand',\n",
       " 'England',\n",
       " 'Australia',\n",
       " 'India',\n",
       " 'South Africa',\n",
       " 'Pakistan',\n",
       " 'Bangladesh',\n",
       " 'West Indies',\n",
       " 'Sri Lanka',\n",
       " 'Afghanistan']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 teams\n",
    "teams= teams[:10]\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"table-body__cell u-center-text\">32</td>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping matches\n",
    "match= soup.find('td', class_=\"table-body__cell u-center-text\")\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['32',\n",
       " '3,793',\n",
       " '28',\n",
       " '3,244',\n",
       " '32',\n",
       " '3,624',\n",
       " '25',\n",
       " '2,459',\n",
       " '27',\n",
       " '2,524',\n",
       " '30',\n",
       " '2,740',\n",
       " '30',\n",
       " '2,523',\n",
       " '32',\n",
       " '2,657',\n",
       " '17',\n",
       " '1,054',\n",
       " '7',\n",
       " '336',\n",
       " '25',\n",
       " '1,145',\n",
       " '10',\n",
       " '452',\n",
       " '20',\n",
       " '764',\n",
       " '14',\n",
       " '524',\n",
       " '11',\n",
       " '330',\n",
       " '9',\n",
       " '190',\n",
       " '14',\n",
       " '232',\n",
       " '6',\n",
       " '97',\n",
       " '13',\n",
       " '0']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match= []\n",
    "for i in soup.find_all('td' ,class_=\"table-body__cell u-center-text\"):\n",
    "    match.append(i.text)\n",
    "match  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17', '32', '28', '32', '25', '27', '30', '30', '32', '17']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matches played by top 10 teams\n",
    "matches=[]\n",
    "for i in match:\n",
    "    matches.append(i.replace(\"\\n\",\"\"))\n",
    "matches=matches[::2]\n",
    "matches.insert(0,\"17\")\n",
    "matches=matches[:10]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"table-body__cell u-center-text\">32</td>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping points\n",
    "point= soup.find('td', class_=\"table-body__cell u-center-text\")\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['32',\n",
       " '3,793',\n",
       " '28',\n",
       " '3,244',\n",
       " '32',\n",
       " '3,624',\n",
       " '25',\n",
       " '2,459',\n",
       " '27',\n",
       " '2,524',\n",
       " '30',\n",
       " '2,740',\n",
       " '30',\n",
       " '2,523',\n",
       " '32',\n",
       " '2,657',\n",
       " '17',\n",
       " '1,054',\n",
       " '7',\n",
       " '336',\n",
       " '25',\n",
       " '1,145',\n",
       " '10',\n",
       " '452',\n",
       " '20',\n",
       " '764',\n",
       " '14',\n",
       " '524',\n",
       " '11',\n",
       " '330',\n",
       " '9',\n",
       " '190',\n",
       " '14',\n",
       " '232',\n",
       " '6',\n",
       " '97',\n",
       " '13',\n",
       " '0']"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point= []\n",
    "for i in soup.find_all('td', class_=\"table-body__cell u-center-text\"):\n",
    "    point.append(i.text)\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,054',\n",
       " '3,793',\n",
       " '3,244',\n",
       " '3,624',\n",
       " '2,459',\n",
       " '2,524',\n",
       " '2,740',\n",
       " '2,523',\n",
       " '2,657',\n",
       " '1,054']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping points of top 10 teams\n",
    "points=[]\n",
    "for i in point:\n",
    "    points.append(i.replace(\"\\n\",\"\"))\n",
    "points=points[1::2]\n",
    "points.insert(0,\"2,054\")\n",
    "points=points[:10]\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"table-body__cell u-text-right rating\">119</td>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Rating\n",
    "rating= soup.find(\"td\" ,class_=\"table-body__cell u-text-right rating\")\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['119',\n",
       " '116',\n",
       " '113',\n",
       " '98',\n",
       " '93',\n",
       " '91',\n",
       " '84',\n",
       " '83',\n",
       " '62',\n",
       " '48',\n",
       " '46',\n",
       " '45',\n",
       " '38',\n",
       " '37',\n",
       " '30',\n",
       " '21',\n",
       " '17',\n",
       " '16',\n",
       " '0']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating= []\n",
    "for i in soup.find_all(\"td\" ,class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "\n",
    "rating    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['121', '119', '116', '113', '98', '93', '91', '84', '83', '62']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping ratings of top 10 teams\n",
    "ratings=[]\n",
    "for i in rating:\n",
    "    ratings.append(i.replace(\"\\n\",\"\"))\n",
    "ratings.insert(0,\"121\")\n",
    "ratings=ratings[:10]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "print(len(teams), len(matches), len(points), len(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>32</td>\n",
       "      <td>3,793</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>28</td>\n",
       "      <td>3,244</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>32</td>\n",
       "      <td>3,624</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>25</td>\n",
       "      <td>2,459</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>2,524</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>30</td>\n",
       "      <td>2,740</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>30</td>\n",
       "      <td>2,523</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>32</td>\n",
       "      <td>2,657</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points Ratings\n",
       "0   New Zealand      17  2,054     121\n",
       "1       England      32  3,793     119\n",
       "2     Australia      28  3,244     116\n",
       "3         India      32  3,624     113\n",
       "4  South Africa      25  2,459      98\n",
       "5      Pakistan      27  2,524      93\n",
       "6    Bangladesh      30  2,740      91\n",
       "7   West Indies      30  2,523      84\n",
       "8     Sri Lanka      32  2,657      83\n",
       "9   Afghanistan      17  1,054      62"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "df= pd.DataFrame({'Teams':teams, 'Matches':matches, 'Points':points, 'Ratings':ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Top 10 ODI Batters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requests to a server\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page content\n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"rankings-block__banner--name\">Babar Azam</div>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping Batters\n",
    "name= soup.find('div' ,class_=\"rankings-block__banner--name\")\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam',\n",
       " 'Virat Kohli',\n",
       " 'Rohit Sharma',\n",
       " 'Ross Taylor',\n",
       " 'Aaron Finch',\n",
       " 'Jonny Bairstow',\n",
       " 'David Warner',\n",
       " 'Shai Hope',\n",
       " 'Kane Williamson',\n",
       " 'Quinton de Kock']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping top 10 batters\n",
    "player= []\n",
    "for i in soup.find_all('td' ,class_=\"table-body__cell name\"):\n",
    "    player.append(i.text.replace(\"\\n\",\"\"))\n",
    "player.insert(0,\"Babar Azam\")\n",
    "player= player[:10]\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAK', 'IND', 'IND', 'NZ', 'AUS', 'ENG', 'AUS', 'WI', 'NZ', 'SA']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Teams\n",
    "team= []\n",
    "for i in soup.find_all(\"span\" ,class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team.insert(0,\"PAK\")\n",
    "team= team[:10]\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"rankings-block__banner--rating\">873</div>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rating\n",
    "rating= soup.find(\"div\" ,class_=\"rankings-block__banner--rating\")\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['873', '844', '813', '801', '779', '775', '762', '758', '754', '743']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sraping rating of top 10 batters\n",
    "rating= []\n",
    "for i in soup.find_all(\"td\" ,class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text.replace('\\n',\"\"))\n",
    "rating.insert(0,\"873\")\n",
    "rating= rating[:10]\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "print(len(player), len(team), len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player Team rating\n",
       "0       Babar Azam  PAK    873\n",
       "1      Virat Kohli  IND    844\n",
       "2     Rohit Sharma  IND    813\n",
       "3      Ross Taylor   NZ    801\n",
       "4      Aaron Finch  AUS    779\n",
       "5   Jonny Bairstow  ENG    775\n",
       "6     David Warner  AUS    762\n",
       "7        Shai Hope   WI    758\n",
       "8  Kane Williamson   NZ    754\n",
       "9  Quinton de Kock   SA    743"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "mens_odi_batting_rankings= pd.DataFrame({'Player':player, 'Team':team, 'rating':rating})\n",
    "mens_odi_batting_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) Top 10 ODI Bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requests to server\n",
    "page= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page content\n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"rankings-block__banner--name-large\">Trent Boult</div>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowler_name= soup.find('div' ,class_=\"rankings-block__banner--name-large\")\n",
    "bowler_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trent Boult',\n",
       " 'Josh Hazlewood',\n",
       " 'Mujeeb Ur Rahman',\n",
       " 'Chris Woakes',\n",
       " 'Mehedi Hasan',\n",
       " 'Matt Henry',\n",
       " 'Jasprit Bumrah',\n",
       " 'Mitchell Starc',\n",
       " 'Shakib Al Hasan',\n",
       " 'Kagiso Rabada']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping top 10 bowlers\n",
    "bowler_name= []\n",
    "for i in soup.find_all('td' ,class_=\"table-body__cell rankings-table__name name\"):\n",
    "    bowler_name.append(i.text.replace('\\n',\"\"))\n",
    "bowler_name.insert(0,'Trent Boult')\n",
    "bowler_name= bowler_name[:10]\n",
    "bowler_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NZ', 'AUS', 'AFG', 'ENG', 'BAN', 'NZ', 'IND', 'AUS', 'BAN', 'SA']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping teams of respective bowlers\n",
    "team= []\n",
    "for i in soup.find_all('span' ,class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team.insert(0,'NZ')\n",
    "team= team[:10]\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['737', '709', '708', '700', '692', '691', '679', '652', '650', '643']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping rating of respective bowlers\n",
    "rating= []\n",
    "for i in soup.find_all('td' ,class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating.insert(0, '737')\n",
    "rating= rating[:10]\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Finding Length\n",
    "print(len(bowler_name), len(team), len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Rating\n",
       "0       Trent Boult   NZ    737\n",
       "1    Josh Hazlewood  AUS    709\n",
       "2  Mujeeb Ur Rahman  AFG    708\n",
       "3      Chris Woakes  ENG    700\n",
       "4      Mehedi Hasan  BAN    692\n",
       "5        Matt Henry   NZ    691\n",
       "6    Jasprit Bumrah  IND    679\n",
       "7    Mitchell Starc  AUS    652\n",
       "8   Shakib Al Hasan  BAN    650\n",
       "9     Kagiso Rabada   SA    643"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "mens_odi_bowling_rankings= pd.DataFrame({'Player':bowler_name, 'Team':team, 'Rating':rating})\n",
    "mens_odi_bowling_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- ICC Women’s Cricket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Top 10 ODI teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requests to server\n",
    "page= requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page content\n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"u-hide-phablet\">Australia</span>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team= soup.find('span' ,class_=\"u-hide-phablet\")\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'South Africa',\n",
       " 'England',\n",
       " 'India',\n",
       " 'Bangladesh',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Pakistan',\n",
       " 'Ireland',\n",
       " 'Sri Lanka']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping top 10 teams\n",
    "team= []\n",
    "for i in soup.find_all('span' ,class_=\"u-hide-phablet\"):\n",
    "    team.append(i.text)\n",
    "team=team[:10]\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17', '19', '18', '17', '5', '19', '19', '18', '5', '5']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Matches\n",
    "matches=[]\n",
    "for i in soup.find_all('td' ,class_=\"table-body__cell u-center-text\"):\n",
    "    matches.append(i.text)\n",
    "matches= matches[::2]\n",
    "matches.insert(0,'17')\n",
    "matches= matches[:10]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,746',\n",
       " '2,307',\n",
       " '2,148',\n",
       " '1,899',\n",
       " '475',\n",
       " '1,668',\n",
       " '1,658',\n",
       " '1,226',\n",
       " '240',\n",
       " '233']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Points\n",
    "points= []\n",
    "for i in soup.find_all('td' ,class_=\"table-body__cell u-center-text\"):\n",
    "    points.append(i.text)\n",
    "points= points[1::2]\n",
    "points.insert(0, '2,746')\n",
    "points= points[:10]\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['162', '121', '119', '112', '95', '88', '87', '68', '48', '47']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Rating\n",
    "rating= []\n",
    "for i in soup.find_all('td' ,class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "rating.insert(0,'162')\n",
    "rating= rating[:10]\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Finding Length\n",
    "print(len(team),len(matches), len(points), len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>17</td>\n",
       "      <td>2,746</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>19</td>\n",
       "      <td>2,307</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>18</td>\n",
       "      <td>2,148</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>17</td>\n",
       "      <td>1,899</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>475</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>19</td>\n",
       "      <td>1,668</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>19</td>\n",
       "      <td>1,658</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>18</td>\n",
       "      <td>1,226</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>5</td>\n",
       "      <td>233</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points Rating\n",
       "0     Australia      17  2,746    162\n",
       "1  South Africa      19  2,307    121\n",
       "2       England      18  2,148    119\n",
       "3         India      17  1,899    112\n",
       "4    Bangladesh       5    475     95\n",
       "5   New Zealand      19  1,668     88\n",
       "6   West Indies      19  1,658     87\n",
       "7      Pakistan      18  1,226     68\n",
       "8       Ireland       5    240     48\n",
       "9     Sri Lanka       5    233     47"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "top10team_odirankingwomen= pd.DataFrame({'Team':team, 'Matches':matches, 'Points':points, 'Rating':rating})\n",
    "top10team_odirankingwomen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Top 10 women’s ODI Batting players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requests to server\n",
    "page= requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page Content\n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"rankings-block__banner--name-large\">Lizelle Lee</div>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player= soup.find('div' ,class_=\"rankings-block__banner--name-large\")\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lizelle Lee',\n",
       " 'Alyssa Healy',\n",
       " 'Mithali Raj',\n",
       " 'Tammy Beaumont',\n",
       " 'Amy Satterthwaite',\n",
       " 'Smriti Mandhana',\n",
       " 'Meg Lanning',\n",
       " 'Beth Mooney',\n",
       " 'Stafanie Taylor',\n",
       " 'Heather Knight']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping top 10 players\n",
    "players=[]\n",
    "for i in soup.find_all('td' ,class_=\"table-body__cell rankings-table__name name\"):\n",
    "    players.append(i.text.replace('\\n',\"\"))\n",
    "players.insert(0, \"Lizelle Lee\")\n",
    "players= players[:10]\n",
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SA', 'AUS', 'IND', 'ENG', 'NZ', 'IND', 'AUS', 'AUS', 'WI', 'ENG']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping teams\n",
    "team= []\n",
    "for i in soup.find_all('span' ,class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team.insert(0,\"SA\")\n",
    "team= team[:10]\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['761', '750', '738', '728', '717', '710', '699', '690', '676', '674']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping rating\n",
    "rating=[]\n",
    "for i in soup.find_all('td' ,class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating.insert(0, \"761\")\n",
    "rating= rating[:10]\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Finding Length\n",
    "print(len(players), len(team), len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Players</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Heather Knight</td>\n",
       "      <td>ENG</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Players Team Rating\n",
       "0        Lizelle Lee   SA    761\n",
       "1       Alyssa Healy  AUS    750\n",
       "2        Mithali Raj  IND    738\n",
       "3     Tammy Beaumont  ENG    728\n",
       "4  Amy Satterthwaite   NZ    717\n",
       "5    Smriti Mandhana  IND    710\n",
       "6        Meg Lanning  AUS    699\n",
       "7        Beth Mooney  AUS    690\n",
       "8    Stafanie Taylor   WI    676\n",
       "9     Heather Knight  ENG    674"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame \n",
    "women_odi_batting_rankings= pd.DataFrame({'Players':players, 'Team':team, 'Rating':rating})\n",
    "women_odi_batting_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) Top 10 women’s ODI all-rounder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requests to server \n",
    "page= requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page Content\n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marizanne Kapp',\n",
       " 'Natalie Sciver',\n",
       " 'Ellyse Perry',\n",
       " 'Stafanie Taylor',\n",
       " 'Deepti Sharma',\n",
       " 'Ashleigh Gardner',\n",
       " 'Dane van Niekerk',\n",
       " 'Hayley Matthews',\n",
       " 'Jess Jonassen',\n",
       " 'Katherine Brunt']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping top 10 all-rounders\n",
    "players= []\n",
    "for i in soup.find_all('td' ,class_=\"table-body__cell rankings-table__name name\"):\n",
    "    players.append(i.text.replace('\\n', \"\"))\n",
    "players.insert(0, \"Marizanne Kapp\")\n",
    "players= players[:10]\n",
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SA', 'ENG', 'AUS', 'WI', 'IND', 'AUS', 'SA', 'WI', 'AUS', 'ENG']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping teams\n",
    "team= []\n",
    "for i in soup.find_all('span' ,class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team.insert(0, \"SA\")\n",
    "team= team[:10]\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['384', '372', '365', '319', '299', '275', '274', '272', '272', '272']"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping rating\n",
    "rating= []\n",
    "for i in soup.find_all('td' ,class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating.insert(0, \"384\")\n",
    "rating= rating[:10]\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Finding Length\n",
    "print(len(players), len(team), len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Rating\n",
       "0    Marizanne Kapp   SA    384\n",
       "1    Natalie Sciver  ENG    372\n",
       "2      Ellyse Perry  AUS    365\n",
       "3   Stafanie Taylor   WI    319\n",
       "4     Deepti Sharma  IND    299\n",
       "5  Ashleigh Gardner  AUS    275\n",
       "6  Dane van Niekerk   SA    274\n",
       "7   Hayley Matthews   WI    272\n",
       "8     Jess Jonassen  AUS    272\n",
       "9   Katherine Brunt  ENG    272"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "women_odi_allrounders_rankings= pd.DataFrame({'Player':players, 'Team':team, 'Rating':rating})\n",
    "women_odi_allrounders_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7- CoreyMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requests to server\n",
    "page= requests.get(\"https://coreyms.com/\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page content\n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"entry-title-link\" href=\"https://coreyms.com/development/python/python-tutorial-zip-files-creating-and-extracting-zip-archives\" rel=\"bookmark\">Python Tutorial: Zip Files – Creating and Extracting Zip Archives</a>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping heading\n",
    "heading= soup.find('a' ,class_=\"entry-title-link\")\n",
    "heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python Tutorial: Zip Files – Creating and Extracting Zip Archives'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<time class=\"entry-time\" datetime=\"2019-11-19T13:02:37-05:00\" itemprop=\"datePublished\">November 19, 2019</time>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping date\n",
    "date= soup.find(\"time\", class_= \"entry-time\")\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'November 19, 2019'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"entry-content\" itemprop=\"text\">\n",
       "<p>In this video, we will be learning how to create and extract zip archives. We will start by using the zipfile module, and then we will see how to do this using the shutil module. We will learn how to do this with single files and directories, as well as learning how to use gzip as well. Let’s get started…<br/></p>\n",
       "<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe allowfullscreen=\"true\" class=\"youtube-player\" height=\"360\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation\" src=\"https://www.youtube.com/embed/z0gguhEmWiY?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent\" style=\"border:0;\" width=\"640\"></iframe></span>\n",
       "</div>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping content\n",
    "content= soup.find(\"div\", class_=\"entry-content\")\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this video, we will be learning how to create and extract zip archives. We will start by using the zipfile module, and then we will see how to do this using the shutil module. We will learn how to do this with single files and directories, as well as learning how to use gzip as well. Let’s get started…'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.text.replace('\\n',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python Tutorial: Zip Files – Creating and Extracting Zip Archives',\n",
       " 'Python Data Science Tutorial: Analyzing the 2019 Stack Overflow Developer Survey',\n",
       " 'Python Multiprocessing Tutorial: Run Code in Parallel Using the Multiprocessing Module',\n",
       " 'Python Threading Tutorial: Run Code Concurrently Using the Threading Module',\n",
       " 'Update (2019-09-03)',\n",
       " 'Python Quick Tip: The Difference Between “==” and “is” (Equality vs Identity)',\n",
       " 'Python Tutorial: Calling External Commands Using the Subprocess Module',\n",
       " 'Visual Studio Code (Windows) – Setting up a Python Development Environment and Complete Overview',\n",
       " 'Visual Studio Code (Mac) – Setting up a Python Development Environment and Complete Overview',\n",
       " 'Clarifying the Issues with Mutable Default Arguments']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Multiple headings \n",
    "headings= []\n",
    "for i in soup.find_all('a' ,class_=\"entry-title-link\"):\n",
    "    headings.append(i.text)\n",
    "headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['November 19, 2019',\n",
       " 'October 17, 2019',\n",
       " 'September 21, 2019',\n",
       " 'September 12, 2019',\n",
       " 'September 3, 2019',\n",
       " 'August 6, 2019',\n",
       " 'July 24, 2019',\n",
       " 'May 1, 2019',\n",
       " 'May 1, 2019',\n",
       " 'April 24, 2019']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Multiple dates \n",
    "dates= []\n",
    "for i in soup.find_all(\"time\", class_= \"entry-time\"):\n",
    "    dates.append(i.text)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In this video, we will be learning how to create and extract zip archives. We will start by using the zipfile module, and then we will see how to do this using the shutil module. We will learn how to do this with single files and directories, as well as learning how to use gzip as well. Let’s get started…',\n",
       " 'In this Python Programming video, we will be learning how to download and analyze real-world data from the 2019 Stack Overflow Developer Survey. This is terrific practice for anyone getting into the data science field. We will learn different ways to analyze this data and also some best practices. Let’s get started…',\n",
       " 'In this Python Programming video, we will be learning how to run code in parallel using the multiprocessing module. We will also look at how to process multiple high-resolution images at the same time using a ProcessPoolExecutor from the concurrent.futures module. Let’s get started…',\n",
       " 'In this Python Programming video, we will be learning how to run threads concurrently using the threading module. We will also look at how to download multiple high-resolution images online using a ThreadPoolExecutor from the concurrent.futures module. Let’s get started…',\n",
       " 'Hey everyone. I wanted to give you an update on my videos. I will be releasing videos on threading and multiprocessing within the next week. Thanks so much for your patience. I currently have a temporary recording studio setup at my Airbnb that will allow me to record and edit the threading/multiprocessing videos. I am going to be moving into my new house in 10 days and once I have my recording studio setup then you can expect much faster video releases. I really appreciate how patient everyone has been while I go through this move, especially those of you who are contributing monthly through YouTube ',\n",
       " 'In this Python Programming Tutorial, we will be learning the difference between using “==” and the “is” keyword when doing comparisons. The difference between these is that “==” checks to see if values are equal, and the “is” keyword checks their identity, which means it’s going to check if the values are identical in terms of being the same object in memory. We’ll learn more in the video. Let’s get started…',\n",
       " 'In this Python Programming Tutorial, we will be learning how to run external commands using the subprocess module from the standard library. We will learn how to run commands, capture the output, handle errors, and also how to pipe output into other commands. Let’s get started…',\n",
       " 'In this Python Programming Tutorial, we will be learning how to set up a Python development environment in VSCode on Windows. VSCode is a very nice free editor for writing Python applications and many developers are now switching over to this editor. In this video, we will learn how to install VSCode, get the Python extension installed, how to change Python interpreters, create virtual environments, format/lint our code, how to use Git within VSCode, how to debug our programs, how unit testing works, and more. We have a lot to cover, so let’s go ahead and get started…VSCode on MacOS – https://youtu.be/06I63_p-2A4Timestamps for topics in this tutorial: Installation – 1:13 Python Extension – 5:48 Switching Interpreters – 10:04 Changing Color Themes – 12:35 VSCode Settings – 16:16 Set Default Python – 21:33 Using Virtual Environments – 25:10 IntelliSense – 29:45 Code Formatting – 32:13 Code Linting – 37:06 Code Runner Extension – 39:42 Git Integration – 47:44 Use Different Terminal – 51:07 Debugging – 58:45 Unit Testing – 1:03:25 Zen Mode – 1:09:55',\n",
       " 'In this Python Programming Tutorial, we will be learning how to set up a Python development environment in VSCode on MacOS. VSCode is a very nice free editor for writing Python applications and many developers are now switching over to this editor. In this video, we will learn how to install VSCode, get the Python extension installed, how to change Python interpreters, create virtual environments, format/lint our code, how to use Git within VSCode, how to debug our programs, how unit testing works, and more. We have a lot to cover, so let’s go ahead and get started…VSCode on Windows – https://youtu.be/-nh9rCzPJ20Timestamps for topics in this tutorial: Installation – 1:11 Python Extension – 6:21 Switching Interpreters – 10:16 Changing Color Themes – 13:08 VSCode Settings – 17:12 Set Default Python – 22:24 Using Virtual Environments – 25:52 IntelliSense – 30:28 Code Formatting – 33:08 Code Linting – 38:01 Code Runner Extension – 40:45 Git Integration – 49:05 Debugging – 58:15 Unit Testing – 1:02:38 Zen Mode – 1:10:42 ',\n",
       " 'In this Python Programming Tutorial, we will be clarifying the issues with mutable default arguments. We discussed this in my last video titled “5 Common Python Mistakes and How to Fix Them”, but I received many comments from people who were still confused. So we will be doing a deeper dive to explain exactly what is going on here. Let’s get started…']"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple content\n",
    "content= []\n",
    "for i in soup.find_all(\"div\", class_=\"entry-content\"):\n",
    "    content.append(i.text.replace('\\n',\"\"))\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.youtube.com/embed/z0gguhEmWiY?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping video link\n",
    "youtube_link = soup.find(\"iframe\", class_=\"youtube-player\")['src']\n",
    "youtube_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'z0gguhEmWiY'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping video code \n",
    "video_code = youtube_link.split(\"?\")[0].split(\"/\")[-1]\n",
    "\n",
    "video_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['z0gguhEmWiY',\n",
       " '_P7X8tMplsw',\n",
       " 'fKl2JW_qrso',\n",
       " 'IEEhzQoKtQU',\n",
       " 'mO_dS3rXDIs',\n",
       " '2Fp1N6dof0Y',\n",
       " '-nh9rCzPJ20',\n",
       " '06I63_p-2A4',\n",
       " '_JGmemuINww']"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_codes= []\n",
    "for i in soup.find_all('iframe', class_='youtube-player'):\n",
    "    video_codes.append(i['src'].split(\"?\")[0].split(\"/\")[-1])\n",
    "video_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 9\n"
     ]
    }
   ],
   "source": [
    "# Finding length\n",
    "print(len(headings), len(dates), len(content), len(video_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heading number 5 (update(2019-09-03) do not have any video so no video_code for it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heading</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Tutorial: Zip Files – Creating and Extr...</td>\n",
       "      <td>November 19, 2019</td>\n",
       "      <td>In this video, we will be learning how to crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Data Science Tutorial: Analyzing the 20...</td>\n",
       "      <td>October 17, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Multiprocessing Tutorial: Run Code in P...</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Threading Tutorial: Run Code Concurrent...</td>\n",
       "      <td>September 12, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Update (2019-09-03)</td>\n",
       "      <td>September 3, 2019</td>\n",
       "      <td>Hey everyone. I wanted to give you an update o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Quick Tip: The Difference Between “==” ...</td>\n",
       "      <td>August 6, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Tutorial: Calling External Commands Usi...</td>\n",
       "      <td>July 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Visual Studio Code (Windows) – Setting up a Py...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Visual Studio Code (Mac) – Setting up a Python...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clarifying the Issues with Mutable Default Arg...</td>\n",
       "      <td>April 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Heading                Date  \\\n",
       "0  Python Tutorial: Zip Files – Creating and Extr...   November 19, 2019   \n",
       "1  Python Data Science Tutorial: Analyzing the 20...    October 17, 2019   \n",
       "2  Python Multiprocessing Tutorial: Run Code in P...  September 21, 2019   \n",
       "3  Python Threading Tutorial: Run Code Concurrent...  September 12, 2019   \n",
       "4                                Update (2019-09-03)   September 3, 2019   \n",
       "5  Python Quick Tip: The Difference Between “==” ...      August 6, 2019   \n",
       "6  Python Tutorial: Calling External Commands Usi...       July 24, 2019   \n",
       "7  Visual Studio Code (Windows) – Setting up a Py...         May 1, 2019   \n",
       "8  Visual Studio Code (Mac) – Setting up a Python...         May 1, 2019   \n",
       "9  Clarifying the Issues with Mutable Default Arg...      April 24, 2019   \n",
       "\n",
       "                                             Content  \n",
       "0  In this video, we will be learning how to crea...  \n",
       "1  In this Python Programming video, we will be l...  \n",
       "2  In this Python Programming video, we will be l...  \n",
       "3  In this Python Programming video, we will be l...  \n",
       "4  Hey everyone. I wanted to give you an update o...  \n",
       "5  In this Python Programming Tutorial, we will b...  \n",
       "6  In this Python Programming Tutorial, we will b...  \n",
       "7  In this Python Programming Tutorial, we will b...  \n",
       "8  In this Python Programming Tutorial, we will b...  \n",
       "9  In this Python Programming Tutorial, we will b...  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "df= pd.DataFrame({'Heading':headings, 'Date':dates, 'Content':content})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8- nobroker.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page= requests.get(\"https://www.nobroker.in/property/rent/bangalore/multiple?searchParam=W3sibGF0IjoxMi45NzgzNjkyLCJsb24iOjc3LjY0MDgzNTYsInBsYWNlSWQiOiJDaElKa1FOM0dLUVdyanNSTmhCUUpyaEdEN1UiLCJwbGFjZU5hbWUiOiJJbmRpcmFuYWdhciJ9LHsibGF0IjoxMi45MzA3NzM1LCJsb24iOjc3LjU4MzgzMDIsInBsYWNlSWQiOiJDaElKMmRkbFo1Z1ZyanNSaDFCT0FhZi1vcnMiLCJwbGFjZU5hbWUiOiJKYXlhbmFnYXIifSx7ImxhdCI6MTIuOTk4MTczMiwibG9uIjo3Ny41NTMwNDQ1OTk5OTk5OSwicGxhY2VJZCI6IkNoSUp4Zlc0RFBNOXJqc1JLc05URy01cF9RUSIsInBsYWNlTmFtZSI6IlJhamFqaW5hZ2FyIn1d&radius=2.0&sharedAccomodation=0&city=bangalore&locality=Indiranagar,&locality=Jayanagar,&locality=Rajajinagar\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2 class=\"heading-6 font-semi-bold nb__25Cl7\"><span itemprop=\"name\">2 BHK Flat  For Rent  In Stanalone Building In Dcb Bank</span> <svg class=\"\" style=\"width:24px;height:24px;margin:2px\" type=\"link\" viewbox=\"0 0 24 24\"><path class=\"\" d=\"M18,10.82a1,1,0,0,0-1,1V19a1,1,0,0,1-1,1H5a1,1,0,0,1-1-1V8A1,1,0,0,1,5,7h7.18a1,1,0,0,0,0-2H5A3,3,0,0,0,2,8V19a3,3,0,0,0,3,3H16a3,3,0,0,0,3-3V11.82A1,1,0,0,0,18,10.82Zm3.92-8.2a1,1,0,0,0-.54-.54A1,1,0,0,0,21,2H15a1,1,0,0,0,0,2h3.59L8.29,14.29a1,1,0,0,0,0,1.42,1,1,0,0,0,1.42,0L20,5.41V9a1,1,0,0,0,2,0V3A1,1,0,0,0,21.92,2.62Z\" fill=\"#000000\"></path></svg></h2>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping house_titles \n",
    "house_title= soup.find('h2' ,class_=\"heading-6 font-semi-bold nb__25Cl7\")\n",
    "house_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 BHK Flat  For Rent  In Stanalone Building In Dcb Bank '"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 BHK Flat  For Rent  In Stanalone Building In Dcb Bank ',\n",
       " '1 RK Flat  For Rent  In Rajajinagar ',\n",
       " '3 BHK Apartment  For Rent  In Santa Clara Apartments In Jayanagar ',\n",
       " '2 BHK In Independent House  For Rent  In Jayanagar ',\n",
       " '1 BHK In Independent House  For Rent  In Indiranagar ',\n",
       " '2 BHK In Independent House  For Rent  In Jayanagar ',\n",
       " '2 BHK Apartment  For Rent  In Gokul Lake View Aprtments In Jayanagar ',\n",
       " '2 BHK Flat  For Rent  In Prithvi Kunj  In Rajaji Nagar  ',\n",
       " '3 BHK Apartment  For Rent  In Team Green Wood Apartment In Indira Nagar ',\n",
       " '1 BHK Apartment  For Rent  In Bangalore Apartments In Jayanagar ',\n",
       " '4 BHK In Independent House  For Rent  In Btm 1st Stage ',\n",
       " '2 BHK In Independent House  For Rent  In 7th Cross Road, Jayanagar ',\n",
       " \"3 BHK In Independent House  For Rent  In Jayanagar 4th 't' Block \",\n",
       " '3 BHK Apartment  For Rent  In Indus Signature In Indiranagar ',\n",
       " '2 BHK In Independent House  For Rent  In Jayanagara ',\n",
       " '2 BHK In Independent House  For Rent  In Jayanagara 9th Block, Jayanagar ',\n",
       " '2 BHK Apartment  For Rent  In Srinivasa Residency In Indiranagar ',\n",
       " '1 BHK In Independent House  For Rent  In Tilak Nagar, Jayanagar ',\n",
       " '3 BHK Flat  For Rent  In Standalone. Building..... In Jayanagar East ',\n",
       " '3 BHK Apartment  For Rent  In Santa Clara Apartments In Jayanagar ',\n",
       " '2 BHK Flat  For Rent  In Syed Residency In Jaya Nagar 1st Block, Bairasandra Extension, Jayanagar ',\n",
       " '1 RK In Independent House  For Rent  In Indiranagar  ',\n",
       " '2 BHK In Independent House  For Rent  In Subramanyanagar, 2nd Stage, Rajajinagar ',\n",
       " '3 BHK Flat  For Rent  In Jayanagar ',\n",
       " '2 BHK Flat  For Rent  In Srinidi Nilaya In Indira Nagar ']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple house title\n",
    "house_titles= []\n",
    "for i in soup.find_all('h2' ,class_=\"heading-6 font-semi-bold nb__25Cl7\"):\n",
    "    house_titles.append(i.text)\n",
    "house_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"nb__1EwQz\">no 715 2 nd main d block rajaji nagar 2nd state near Dcb bank  raj kumar road </div>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping location\n",
    "location= soup.find('div', class_=\"nb__1EwQz\")\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no 715 2 nd main d block rajaji nagar 2nd state near Dcb bank  raj kumar road '"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no 715 2 nd main d block rajaji nagar 2nd state near Dcb bank  raj kumar road ',\n",
       " 'Standalone Building, 2nd Block, near O.G. Variar and Sons, Variar Bakery',\n",
       " 'Santa Clara Apartments\\xa0 3rd Rd Cross Rd, 5T Block, Marenahalli, Jayanagar, Bengaluru, Karnataka 560041, India',\n",
       " \"Independent House, D'mart ,RBI Colony , Jayanagar, Bengaluru, Karnataka 560011\",\n",
       " 'Independent House, Near Hotel Ragavendra',\n",
       " 'Independent House, Near Jayanagar Orthopaedic Centre,3rd Cross Rd, K V Layout, LIC Colony, Jayanagar 3rd Block East, Jayanagar, Bengaluru-560011',\n",
       " 'Gokul Lake View Aprtments\\xa0 110/18, 19th Cross Road, Yediyur, Jayanagar, Bengaluru, Karnataka 560070, India',\n",
       " '2nd Block,near Rajajinagar Post Office',\n",
       " 'Team Green Wood Apartment\\xa0 3rd Main Rd, Indira Nagar 1st Stage, H Colony, Indiranagar, Bengaluru, Karnataka 560038, India',\n",
       " 'Bangalore Apartments\\xa0 Ganesha temple',\n",
       " 'Independent House, near Jayadeva hospital',\n",
       " 'Independent House, near Ashoka Pillar, 2nd Block Jayanagar ',\n",
       " 'Independent House, 20th main',\n",
       " 'Indus Signature\\xa0 Indus Signature, Eshwara Layout, Indiranagar, Bengaluru, Karnataka 560008, India',\n",
       " 'Independent House,  9th Block , near Hotel siddique',\n",
       " 'Independent House, hotel siddique',\n",
       " 'Srinivasa Residency\\xa0 HAL 2nd Stage, near Khivraj Bajaj - Indiranagar',\n",
       " 'Independent House, besides Balamuri Ganapathi Temple,',\n",
       " 'BDA shopping complex',\n",
       " 'Santa Clara Apartments\\xa0 Marenahalli, Jayanagar, Bengaluru, Karnataka 560041, India',\n",
       " 'Cake Paradise, 5th Main Road, Canara Bank Colony, LIC Colony, Jayanagar 3rd Block East, Jaya Nagar, Bengaluru, Karnataka, India',\n",
       " 'Independent House, Chinmaya Mission Hospital Rd,  Stage 1, indira nagar metro station ',\n",
       " 'Independent House, 18TH MAIN, A BLOCK SUBRAMANYA NAGAR ',\n",
       " 'Standalone Building, 31st cross 2nd main 7th Block  Jaynagar',\n",
       " '18th b main road']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple location\n",
    "locations= []\n",
    "for i in soup.find_all('div', 'nb__1EwQz'):\n",
    "    locations.append(i.text)\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"nb__FfHqA\">1,400 sqft</div>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping area\n",
    "area= soup.find('div' ,class_=\"nb__FfHqA\")\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,400 sqft'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,400 sqft',\n",
       " '250 sqft',\n",
       " '1,400 sqft',\n",
       " '1,000 sqft',\n",
       " '324 sqft',\n",
       " '800 sqft',\n",
       " '1,532 sqft',\n",
       " '950 sqft',\n",
       " '1,648 sqft',\n",
       " '500 sqft',\n",
       " '2,250 sqft',\n",
       " '1,050 sqft',\n",
       " '2,400 sqft',\n",
       " '1,652 sqft',\n",
       " '850 sqft',\n",
       " '550 sqft',\n",
       " '1,050 sqft',\n",
       " '450 sqft',\n",
       " '2,400 sqft',\n",
       " '1,647 sqft',\n",
       " '1,000 sqft',\n",
       " '350 sqft',\n",
       " '800 sqft',\n",
       " '2,000 sqft',\n",
       " '1,580 sqft']"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple area's\n",
    "area= []\n",
    "for i in soup.find_all('div' ,class_=\"nb__FfHqA\"):\n",
    "    area.append(i.text)\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"nb__27aDo\">₹ 17,000<!-- --> +<span class=\"nb__2uIga\"><div><span class=\"nb__2KN_6\">₹ 500 Maintenance</span><img alt=\"maintenance\" class=\"nb__1cqDQ\" src=\"https://assets.nobroker.in/nb-new/public/Property-Details/maintenance.svg\"/></div></span></div>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping EMI\n",
    "emi= soup.find('div' ,class_=\"nb__27aDo\")\n",
    "emi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'₹ 17,000 +₹ 500 Maintenance'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emi.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 17,000 +₹ 500 Maintenance',\n",
       " '₹ 6,000 +₹ 500 Maintenance',\n",
       " '₹ 27,000 +₹ 3,000 Maintenance',\n",
       " '₹ 21,000No Extra Maintenance',\n",
       " '₹ 10,000 +₹ 200 Maintenance',\n",
       " '₹ 23,000No Extra Maintenance',\n",
       " '₹ 25,000 +₹ 4,500 Maintenance',\n",
       " '₹ 25,000 +₹ 2,000 Maintenance',\n",
       " '₹ 46,000No Extra Maintenance',\n",
       " '₹ 17,000 +₹ 3,000 Maintenance',\n",
       " '₹ 45,800 +₹ 1,200 Maintenance',\n",
       " '₹ 20,500No Extra Maintenance',\n",
       " '₹ 85,000No Extra Maintenance',\n",
       " '₹ 37,000 +₹ 6,500 Maintenance',\n",
       " '₹ 20,000No Extra Maintenance',\n",
       " '₹ 16,000No Extra Maintenance',\n",
       " '₹ 24,000 +₹ 2,000 Maintenance',\n",
       " '₹ 9,000No Extra Maintenance',\n",
       " '₹ 36,000No Extra Maintenance',\n",
       " '₹ 30,000 +₹ 3,000 Maintenance',\n",
       " '₹ 23,000No Extra Maintenance',\n",
       " '₹ 20,000No Extra Maintenance',\n",
       " '₹ 17,000No Extra Maintenance',\n",
       " '₹ 35,000No Extra Maintenance',\n",
       " '₹ 29,000No Extra Maintenance']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple EMI's\n",
    "emi= []\n",
    "for i in soup.find_all('div' ,class_=\"nb__27aDo\"):\n",
    "    emi.append(i.text)\n",
    "emi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "# Finding length \n",
    "print(len(house_titles), len(locations), len(area), len(emi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>EMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 BHK Flat  For Rent  In Stanalone Building In...</td>\n",
       "      <td>no 715 2 nd main d block rajaji nagar 2nd stat...</td>\n",
       "      <td>1,400 sqft</td>\n",
       "      <td>₹ 17,000 +₹ 500 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 RK Flat  For Rent  In Rajajinagar</td>\n",
       "      <td>Standalone Building, 2nd Block, near O.G. Vari...</td>\n",
       "      <td>250 sqft</td>\n",
       "      <td>₹ 6,000 +₹ 500 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 BHK Apartment  For Rent  In Santa Clara Apar...</td>\n",
       "      <td>Santa Clara Apartments  3rd Rd Cross Rd, 5T Bl...</td>\n",
       "      <td>1,400 sqft</td>\n",
       "      <td>₹ 27,000 +₹ 3,000 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In Jayan...</td>\n",
       "      <td>Independent House, D'mart ,RBI Colony , Jayana...</td>\n",
       "      <td>1,000 sqft</td>\n",
       "      <td>₹ 21,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 BHK In Independent House  For Rent  In Indir...</td>\n",
       "      <td>Independent House, Near Hotel Ragavendra</td>\n",
       "      <td>324 sqft</td>\n",
       "      <td>₹ 10,000 +₹ 200 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In Jayan...</td>\n",
       "      <td>Independent House, Near Jayanagar Orthopaedic ...</td>\n",
       "      <td>800 sqft</td>\n",
       "      <td>₹ 23,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 BHK Apartment  For Rent  In Gokul Lake View ...</td>\n",
       "      <td>Gokul Lake View Aprtments  110/18, 19th Cross ...</td>\n",
       "      <td>1,532 sqft</td>\n",
       "      <td>₹ 25,000 +₹ 4,500 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 BHK Flat  For Rent  In Prithvi Kunj  In Raja...</td>\n",
       "      <td>2nd Block,near Rajajinagar Post Office</td>\n",
       "      <td>950 sqft</td>\n",
       "      <td>₹ 25,000 +₹ 2,000 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 BHK Apartment  For Rent  In Team Green Wood ...</td>\n",
       "      <td>Team Green Wood Apartment  3rd Main Rd, Indira...</td>\n",
       "      <td>1,648 sqft</td>\n",
       "      <td>₹ 46,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1 BHK Apartment  For Rent  In Bangalore Apartm...</td>\n",
       "      <td>Bangalore Apartments  Ganesha temple</td>\n",
       "      <td>500 sqft</td>\n",
       "      <td>₹ 17,000 +₹ 3,000 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4 BHK In Independent House  For Rent  In Btm 1...</td>\n",
       "      <td>Independent House, near Jayadeva hospital</td>\n",
       "      <td>2,250 sqft</td>\n",
       "      <td>₹ 45,800 +₹ 1,200 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In 7th C...</td>\n",
       "      <td>Independent House, near Ashoka Pillar, 2nd Blo...</td>\n",
       "      <td>1,050 sqft</td>\n",
       "      <td>₹ 20,500No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3 BHK In Independent House  For Rent  In Jayan...</td>\n",
       "      <td>Independent House, 20th main</td>\n",
       "      <td>2,400 sqft</td>\n",
       "      <td>₹ 85,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3 BHK Apartment  For Rent  In Indus Signature ...</td>\n",
       "      <td>Indus Signature  Indus Signature, Eshwara Layo...</td>\n",
       "      <td>1,652 sqft</td>\n",
       "      <td>₹ 37,000 +₹ 6,500 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In Jayan...</td>\n",
       "      <td>Independent House,  9th Block , near Hotel sid...</td>\n",
       "      <td>850 sqft</td>\n",
       "      <td>₹ 20,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In Jayan...</td>\n",
       "      <td>Independent House, hotel siddique</td>\n",
       "      <td>550 sqft</td>\n",
       "      <td>₹ 16,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2 BHK Apartment  For Rent  In Srinivasa Reside...</td>\n",
       "      <td>Srinivasa Residency  HAL 2nd Stage, near Khivr...</td>\n",
       "      <td>1,050 sqft</td>\n",
       "      <td>₹ 24,000 +₹ 2,000 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1 BHK In Independent House  For Rent  In Tilak...</td>\n",
       "      <td>Independent House, besides Balamuri Ganapathi ...</td>\n",
       "      <td>450 sqft</td>\n",
       "      <td>₹ 9,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3 BHK Flat  For Rent  In Standalone. Building....</td>\n",
       "      <td>BDA shopping complex</td>\n",
       "      <td>2,400 sqft</td>\n",
       "      <td>₹ 36,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3 BHK Apartment  For Rent  In Santa Clara Apar...</td>\n",
       "      <td>Santa Clara Apartments  Marenahalli, Jayanagar...</td>\n",
       "      <td>1,647 sqft</td>\n",
       "      <td>₹ 30,000 +₹ 3,000 Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2 BHK Flat  For Rent  In Syed Residency In Jay...</td>\n",
       "      <td>Cake Paradise, 5th Main Road, Canara Bank Colo...</td>\n",
       "      <td>1,000 sqft</td>\n",
       "      <td>₹ 23,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1 RK In Independent House  For Rent  In Indira...</td>\n",
       "      <td>Independent House, Chinmaya Mission Hospital R...</td>\n",
       "      <td>350 sqft</td>\n",
       "      <td>₹ 20,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2 BHK In Independent House  For Rent  In Subra...</td>\n",
       "      <td>Independent House, 18TH MAIN, A BLOCK SUBRAMAN...</td>\n",
       "      <td>800 sqft</td>\n",
       "      <td>₹ 17,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3 BHK Flat  For Rent  In Jayanagar</td>\n",
       "      <td>Standalone Building, 31st cross 2nd main 7th B...</td>\n",
       "      <td>2,000 sqft</td>\n",
       "      <td>₹ 35,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2 BHK Flat  For Rent  In Srinidi Nilaya In Ind...</td>\n",
       "      <td>18th b main road</td>\n",
       "      <td>1,580 sqft</td>\n",
       "      <td>₹ 29,000No Extra Maintenance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          House Title  \\\n",
       "0   2 BHK Flat  For Rent  In Stanalone Building In...   \n",
       "1                1 RK Flat  For Rent  In Rajajinagar    \n",
       "2   3 BHK Apartment  For Rent  In Santa Clara Apar...   \n",
       "3   2 BHK In Independent House  For Rent  In Jayan...   \n",
       "4   1 BHK In Independent House  For Rent  In Indir...   \n",
       "5   2 BHK In Independent House  For Rent  In Jayan...   \n",
       "6   2 BHK Apartment  For Rent  In Gokul Lake View ...   \n",
       "7   2 BHK Flat  For Rent  In Prithvi Kunj  In Raja...   \n",
       "8   3 BHK Apartment  For Rent  In Team Green Wood ...   \n",
       "9   1 BHK Apartment  For Rent  In Bangalore Apartm...   \n",
       "10  4 BHK In Independent House  For Rent  In Btm 1...   \n",
       "11  2 BHK In Independent House  For Rent  In 7th C...   \n",
       "12  3 BHK In Independent House  For Rent  In Jayan...   \n",
       "13  3 BHK Apartment  For Rent  In Indus Signature ...   \n",
       "14  2 BHK In Independent House  For Rent  In Jayan...   \n",
       "15  2 BHK In Independent House  For Rent  In Jayan...   \n",
       "16  2 BHK Apartment  For Rent  In Srinivasa Reside...   \n",
       "17  1 BHK In Independent House  For Rent  In Tilak...   \n",
       "18  3 BHK Flat  For Rent  In Standalone. Building....   \n",
       "19  3 BHK Apartment  For Rent  In Santa Clara Apar...   \n",
       "20  2 BHK Flat  For Rent  In Syed Residency In Jay...   \n",
       "21  1 RK In Independent House  For Rent  In Indira...   \n",
       "22  2 BHK In Independent House  For Rent  In Subra...   \n",
       "23                3 BHK Flat  For Rent  In Jayanagar    \n",
       "24  2 BHK Flat  For Rent  In Srinidi Nilaya In Ind...   \n",
       "\n",
       "                                             Location        Area  \\\n",
       "0   no 715 2 nd main d block rajaji nagar 2nd stat...  1,400 sqft   \n",
       "1   Standalone Building, 2nd Block, near O.G. Vari...    250 sqft   \n",
       "2   Santa Clara Apartments  3rd Rd Cross Rd, 5T Bl...  1,400 sqft   \n",
       "3   Independent House, D'mart ,RBI Colony , Jayana...  1,000 sqft   \n",
       "4            Independent House, Near Hotel Ragavendra    324 sqft   \n",
       "5   Independent House, Near Jayanagar Orthopaedic ...    800 sqft   \n",
       "6   Gokul Lake View Aprtments  110/18, 19th Cross ...  1,532 sqft   \n",
       "7              2nd Block,near Rajajinagar Post Office    950 sqft   \n",
       "8   Team Green Wood Apartment  3rd Main Rd, Indira...  1,648 sqft   \n",
       "9                Bangalore Apartments  Ganesha temple    500 sqft   \n",
       "10          Independent House, near Jayadeva hospital  2,250 sqft   \n",
       "11  Independent House, near Ashoka Pillar, 2nd Blo...  1,050 sqft   \n",
       "12                       Independent House, 20th main  2,400 sqft   \n",
       "13  Indus Signature  Indus Signature, Eshwara Layo...  1,652 sqft   \n",
       "14  Independent House,  9th Block , near Hotel sid...    850 sqft   \n",
       "15                  Independent House, hotel siddique    550 sqft   \n",
       "16  Srinivasa Residency  HAL 2nd Stage, near Khivr...  1,050 sqft   \n",
       "17  Independent House, besides Balamuri Ganapathi ...    450 sqft   \n",
       "18                               BDA shopping complex  2,400 sqft   \n",
       "19  Santa Clara Apartments  Marenahalli, Jayanagar...  1,647 sqft   \n",
       "20  Cake Paradise, 5th Main Road, Canara Bank Colo...  1,000 sqft   \n",
       "21  Independent House, Chinmaya Mission Hospital R...    350 sqft   \n",
       "22  Independent House, 18TH MAIN, A BLOCK SUBRAMAN...    800 sqft   \n",
       "23  Standalone Building, 31st cross 2nd main 7th B...  2,000 sqft   \n",
       "24                                   18th b main road  1,580 sqft   \n",
       "\n",
       "                              EMI  \n",
       "0     ₹ 17,000 +₹ 500 Maintenance  \n",
       "1      ₹ 6,000 +₹ 500 Maintenance  \n",
       "2   ₹ 27,000 +₹ 3,000 Maintenance  \n",
       "3    ₹ 21,000No Extra Maintenance  \n",
       "4     ₹ 10,000 +₹ 200 Maintenance  \n",
       "5    ₹ 23,000No Extra Maintenance  \n",
       "6   ₹ 25,000 +₹ 4,500 Maintenance  \n",
       "7   ₹ 25,000 +₹ 2,000 Maintenance  \n",
       "8    ₹ 46,000No Extra Maintenance  \n",
       "9   ₹ 17,000 +₹ 3,000 Maintenance  \n",
       "10  ₹ 45,800 +₹ 1,200 Maintenance  \n",
       "11   ₹ 20,500No Extra Maintenance  \n",
       "12   ₹ 85,000No Extra Maintenance  \n",
       "13  ₹ 37,000 +₹ 6,500 Maintenance  \n",
       "14   ₹ 20,000No Extra Maintenance  \n",
       "15   ₹ 16,000No Extra Maintenance  \n",
       "16  ₹ 24,000 +₹ 2,000 Maintenance  \n",
       "17    ₹ 9,000No Extra Maintenance  \n",
       "18   ₹ 36,000No Extra Maintenance  \n",
       "19  ₹ 30,000 +₹ 3,000 Maintenance  \n",
       "20   ₹ 23,000No Extra Maintenance  \n",
       "21   ₹ 20,000No Extra Maintenance  \n",
       "22   ₹ 17,000No Extra Maintenance  \n",
       "23   ₹ 35,000No Extra Maintenance  \n",
       "24   ₹ 29,000No Extra Maintenance  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "df= pd.DataFrame({'House Title':house_titles, 'Location': locations, 'Area':area, 'EMI':emi})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9- dineout.co.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requests to server\n",
    "page= requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page content \n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"restnt-info cursor\" data-gatype=\"RestaurantNameClick\"><a analytics-action=\"RestaurantCardClick\" analytics-label=\"86792_Castle Barbeque\" class=\"restnt-name ellipsis\" data-w-onclick=\"sendAnalyticsCommon|w1-restarant\" href=\"/delhi/castle-barbeque-connaught-place-central-delhi-86792\">Castle Barbeque</a><div class=\"restnt-loc ellipsis\" data-w-onclick=\"stopClickPropagation|w1-restarant\"><a data-name=\"Connaught Place\" data-type=\"LocalityClick\" href=\"/delhi-restaurants/central-delhi/connaught-place\">Connaught Place</a>, <a data-name=\"Central Delhi\" data-type=\"AreaClick\" href=\"/delhi-restaurants/central-delhi\">Central Delhi</a></div></div>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Restaurant name\n",
    "name=soup.find('div', class_='restnt-info cursor')\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Castle BarbequeConnaught Place, Central Delhi'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"double-line-ellipsis\"><span>₹ 2,000 for 2 (approx)</span><span> | </span><a data-w-onclick=\"stopClickPropagation|w1-restarant\" href=\"/delhi-restaurants/chinese-cuisine\">Chinese</a><span>, </span><a data-w-onclick=\"stopClickPropagation|w1-restarant\" href=\"/delhi-restaurants/north-indian-cuisine\">North Indian</a></span>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Cuisine\n",
    "cuisine= soup.find('span', class_='double-line-ellipsis')\n",
    "cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chinese,'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine.text.split()[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"restnt-loc ellipsis\" data-w-onclick=\"stopClickPropagation|w1-restarant\"><a data-name=\"Connaught Place\" data-type=\"LocalityClick\" href=\"/delhi-restaurants/central-delhi/connaught-place\">Connaught Place</a>, <a data-name=\"Central Delhi\" data-type=\"AreaClick\" href=\"/delhi-restaurants/central-delhi\">Central Delhi</a></div>"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Location\n",
    "location= soup.find('div',class_='restnt-loc ellipsis')\n",
    "location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connaught Place, Central Delhi'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"restnt-rating rating-4\">3.5</div>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping rating\n",
    "rating= soup.find('div',class_='restnt-rating rating-4')\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Castle BarbequeConnaught Place, Central Delhi',\n",
       " 'Jungle Jamboree3CS Mall,Lajpat Nagar - 3, South Delhi',\n",
       " 'Castle BarbequePacific Mall,Tagore Garden, West Delhi',\n",
       " 'Cafe KnoshThe Leela Ambience Convention Hotel,Shahdara, East Delhi',\n",
       " 'The Barbeque CompanyGardens Galleria,Sector 38A, Noida',\n",
       " 'India GrillHilton Garden Inn,Saket, South Delhi',\n",
       " 'Delhi BarbequeTaurus Sarovar Portico,Mahipalpur, South Delhi',\n",
       " 'The Monarch - Bar Be Que VillageIndirapuram Habitat Centre,Indirapuram, Ghaziabad',\n",
       " 'World CafeVibe by The Lalit Traveller,Sector 35, Faridabad',\n",
       " 'Indian Grill RoomSuncity Business Tower,Golf Course Road, Gurgaon',\n",
       " 'Mad 4 Bar B QueSector 29, Faridabad',\n",
       " 'Barbeque 29NIT, Faridabad',\n",
       " 'GlasshouseDoubleTree By Hilton Gurugram Baani Square,Sector 50, Gurgaon']"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple names \n",
    "names= []\n",
    "for i in soup.find_all('div',class_='restnt-info cursor'):\n",
    "    names.append(i.text)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chinese,',\n",
       " 'Barbecue,',\n",
       " 'Chinese,',\n",
       " 'Multi-Cuisine,',\n",
       " 'Barbecue,',\n",
       " 'North',\n",
       " 'Barbecue,',\n",
       " 'North',\n",
       " 'North',\n",
       " 'North',\n",
       " 'North',\n",
       " 'North',\n",
       " 'Multi-Cuisine,']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple cuisine\n",
    "Cuisine= []\n",
    "for i in soup.find_all('span', class_='double-line-ellipsis'):\n",
    "    Cuisine.append(i.text.split()[6])\n",
    "Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Connaught Place, Central Delhi',\n",
       " '3CS Mall,Lajpat Nagar - 3, South Delhi',\n",
       " 'Pacific Mall,Tagore Garden, West Delhi',\n",
       " 'The Leela Ambience Convention Hotel,Shahdara, East Delhi',\n",
       " 'Gardens Galleria,Sector 38A, Noida',\n",
       " 'Hilton Garden Inn,Saket, South Delhi',\n",
       " 'Taurus Sarovar Portico,Mahipalpur, South Delhi',\n",
       " 'Indirapuram Habitat Centre,Indirapuram, Ghaziabad',\n",
       " 'Vibe by The Lalit Traveller,Sector 35, Faridabad',\n",
       " 'Suncity Business Tower,Golf Course Road, Gurgaon',\n",
       " 'Sector 29, Faridabad',\n",
       " 'NIT, Faridabad',\n",
       " 'DoubleTree By Hilton Gurugram Baani Square,Sector 50, Gurgaon']"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple location\n",
    "locations= []\n",
    "for i in soup.find_all('div', class_='restnt-loc ellipsis'):\n",
    "    locations.append(i.text)\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.5',\n",
       " '3.9',\n",
       " '4',\n",
       " '4.3',\n",
       " '4',\n",
       " '3.9',\n",
       " '3.7',\n",
       " '3.9',\n",
       " '4.2',\n",
       " '4.3',\n",
       " '3.7',\n",
       " '4.3',\n",
       " '4.1']"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple rating\n",
    "ratings= []\n",
    "for i in soup.find_all('div',class_='restnt-rating rating-4'):\n",
    "    ratings.append(i.text)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/a/k/p59633-16046474755fa4fa33c0e92.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/j/o/p38113-15959192065f1fcb666130c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/j/v/p406-163401663361651d79326d0.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/q/d/p79307-16051787075fad15532bd7c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/v/t/p2687-1482477169585cce712b90f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/v/f/p52501-16006856545f68865616659.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/n/o/p34822-15599107305cfa594a13c24.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/p/y/p12366-1466935020576fa6ecdc359.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/y/y/p549-15143767525a438e30b3e19.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/j/e/p43488-15295778165b2b8158ceeef.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/w/r/p58842-15624171585d209806d9143.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/9/m/f/p9875-16057921085fb6716cc44f8.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple images\n",
    "images= []\n",
    "for i in soup.find_all('img', class_='no-img'):\n",
    "    images.append(i['data-src'])\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13 13 13 13\n"
     ]
    }
   ],
   "source": [
    "# Finding length\n",
    "print(len(names),len(locations),len(Cuisine),len(ratings),len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurants Names</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Images_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Chinese,</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...</td>\n",
       "      <td>Barbecue,</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle BarbequePacific Mall,Tagore Garden, Wes...</td>\n",
       "      <td>Chinese,</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>Multi-Cuisine,</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>Barbecue,</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>North</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>Barbecue,</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>North</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World CafeVibe by The Lalit Traveller,Sector 3...</td>\n",
       "      <td>North</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>North</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B QueSector 29, Faridabad</td>\n",
       "      <td>North</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29NIT, Faridabad</td>\n",
       "      <td>North</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GlasshouseDoubleTree By Hilton Gurugram Baani ...</td>\n",
       "      <td>Multi-Cuisine,</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Restaurants Names         Cuisine  \\\n",
       "0       Castle BarbequeConnaught Place, Central Delhi        Chinese,   \n",
       "1   Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...       Barbecue,   \n",
       "2   Castle BarbequePacific Mall,Tagore Garden, Wes...        Chinese,   \n",
       "3   Cafe KnoshThe Leela Ambience Convention Hotel,...  Multi-Cuisine,   \n",
       "4   The Barbeque CompanyGardens Galleria,Sector 38...       Barbecue,   \n",
       "5     India GrillHilton Garden Inn,Saket, South Delhi           North   \n",
       "6   Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...       Barbecue,   \n",
       "7   The Monarch - Bar Be Que VillageIndirapuram Ha...           North   \n",
       "8   World CafeVibe by The Lalit Traveller,Sector 3...           North   \n",
       "9   Indian Grill RoomSuncity Business Tower,Golf C...           North   \n",
       "10                Mad 4 Bar B QueSector 29, Faridabad           North   \n",
       "11                          Barbeque 29NIT, Faridabad           North   \n",
       "12  GlasshouseDoubleTree By Hilton Gurugram Baani ...  Multi-Cuisine,   \n",
       "\n",
       "                                            Locations Ratings  \\\n",
       "0                      Connaught Place, Central Delhi     3.5   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi       4   \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "4                  Gardens Galleria,Sector 38A, Noida       4   \n",
       "5                Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.9   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad     4.2   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "10                               Sector 29, Faridabad     3.7   \n",
       "11                                     NIT, Faridabad     4.3   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...     4.1   \n",
       "\n",
       "                                           Images_URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "df= pd.DataFrame({'Restaurants Names':names, 'Cuisine':Cuisine, 'Locations':locations,'Ratings':ratings, 'Images_URL':images })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10- bewakoof.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requests to a server \n",
    "page= requests.get('https://www.bewakoof.com/women-tshirts?ga_q=tshirts')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page content\n",
    "soup= BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"discountedPriceText\">₹ <b>199</b></span>"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping price\n",
    "price= soup.find('span', class_=\"discountedPriceText\")\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'₹ 199'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 199',\n",
       " '₹ 149',\n",
       " '₹ 549',\n",
       " '₹ 199',\n",
       " '₹ 199',\n",
       " '₹ 999',\n",
       " '₹ 199',\n",
       " '₹ 349',\n",
       " '₹ 249',\n",
       " '₹ 249']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple product price\n",
    "Price= []\n",
    "for i in soup.find_all('span', class_='discountedPriceText'):\n",
    "    Price.append(i.text)\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://images.bewakoof.com/t320/believe-in-miracles-half-sleeve-t-shirt-bold-red-women-s-half-sleeve-printed-t-shirt-286440-1600698999.jpg',\n",
       " 'https://images.bewakoof.com/t320/proud-to-be-indian-half-sleeve-t-shirt-women-s-half-sleeve-printed-t-shirt-276436-1595823765.jpg',\n",
       " 'https://images.bewakoof.com/t320/all-we-have-half-sleeve-t-shirt-meteor-grey-women-s-half-sleeve-printed-t-shirt-287646-1601034494.jpg',\n",
       " 'https://images.bewakoof.com/t320/stay-classy-minnie-half-sleeve-printed-t-shirts-dl-women-s-half-sleeve-printed-t-shirt-367242-1625470443.jpg',\n",
       " 'https://images.bewakoof.com/t320/hotter-than-hell-half-sleeve-t-shirt-women-s-half-sleeve-printed-t-shirt-291787-1603126208.jpg',\n",
       " 'https://images.bewakoof.com/t320/jerry-relax-half-sleeve-printed-t-shirt-tjl-navy-blue-women-s-half-sleeve-printed-t-shirt-295661-1603697818.jpg',\n",
       " 'https://images.bewakoof.com/t320/sweet-sass-half-sleeve-t-shirt-dl-women-s-half-sleeve-printed-t-shirt-390752-1629266399.jpg',\n",
       " 'https://images.bewakoof.com/t320/more-reasons-boyfriend-t-shirt-women-s-printed-boyfriend-t-shirts-390632-1629185213.jpg',\n",
       " 'https://images.bewakoof.com/t320/the-chibi-cat-half-sleeve-printed-t-shirt-women-s-half-sleeve-printed-t-shirt-364771-1624277530.gif',\n",
       " 'https://images.bewakoof.com/t320/daffy-awesome-half-sleeve-t-shirt-ltl-women-s-half-sleeve-printed-t-shirt-276664-1595675945.jpg']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping images\n",
    "images= []\n",
    "for i in soup.find_all('img',class_='productImgTag'):\n",
    "    images.append(i['src'])\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"productCardDetail\"><div><h3 id=\"\">Believe In Miracles Half Sleeve T-Shirt Bold Red</h3></div><div class=\"productPriceBox clearfix\"><span class=\"discountedPriceText\">₹ <b>199</b></span><span class=\"actualPriceText\">549</span><span class=\"sellingFastBox\"></span><div class=\"loyaltyPriceBox\"><h6><b>₹<!-- -->179</b>For TriBe Members</h6></div> </div></div>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Product Name\n",
    "Name= soup.find('div', class_=\"productCardDetail\")\n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Believe In Miracles Half Sleeve T-Shirt Bold Red₹ 199549₹179For TriBe Members '"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Believe In Miracles Half Sleeve T-Shirt Bold Red₹ 199549₹179For TriBe Members ',\n",
       " 'Proud To Be Indian Half Sleeve T-Shirt - Bold Red₹ 149499₹129For TriBe Members ',\n",
       " 'All We Have Half Sleeve T-Shirt Meteor Grey₹ 549FEW LEFT₹479For TriBe Members ',\n",
       " 'Stay Classy Minnie Half Sleeve Printed T-shirt (DL)₹ 199799₹179For TriBe Members ',\n",
       " 'Hotter Than Hell Half Sleeve T-shirt₹ 199599₹179For TriBe Members ',\n",
       " 'Jerry Relax Half Sleeve Printed T-Shirt (TJL) Navy Blue₹ 999FEW LEFT₹879For TriBe Members ',\n",
       " 'Sweet Sass Half Sleeve T-shirt (DL)₹ 199799₹179For TriBe Members ',\n",
       " 'More Reasons Boyfriend T-shirt₹ 349799₹319For TriBe Members ',\n",
       " 'The Chibi Cat Half Sleeve Printed T-Shirt₹ 249799₹229For TriBe Members ',\n",
       " 'Daffy Awesome Half Sleeve T-Shirt (LTL)₹ 249549FEW LEFT₹229For TriBe Members ']"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping multiple names\n",
    "names= []\n",
    "for i in soup.find_all('div', class_=\"productCardDetail\"):\n",
    "    names.append(i.text)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Checking length\n",
    "print(len(Price), len(images), len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Believe In Miracles Half Sleeve T-Shirt Bold R...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/believe-in-mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Proud To Be Indian Half Sleeve T-Shirt - Bold ...</td>\n",
       "      <td>₹ 149</td>\n",
       "      <td>https://images.bewakoof.com/t320/proud-to-be-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All We Have Half Sleeve T-Shirt Meteor Grey₹ 5...</td>\n",
       "      <td>₹ 549</td>\n",
       "      <td>https://images.bewakoof.com/t320/all-we-have-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stay Classy Minnie Half Sleeve Printed T-shirt...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/stay-classy-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotter Than Hell Half Sleeve T-shirt₹ 199599₹1...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/hotter-than-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jerry Relax Half Sleeve Printed T-Shirt (TJL) ...</td>\n",
       "      <td>₹ 999</td>\n",
       "      <td>https://images.bewakoof.com/t320/jerry-relax-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sweet Sass Half Sleeve T-shirt (DL)₹ 199799₹17...</td>\n",
       "      <td>₹ 199</td>\n",
       "      <td>https://images.bewakoof.com/t320/sweet-sass-ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>More Reasons Boyfriend T-shirt₹ 349799₹319For ...</td>\n",
       "      <td>₹ 349</td>\n",
       "      <td>https://images.bewakoof.com/t320/more-reasons-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Chibi Cat Half Sleeve Printed T-Shirt₹ 249...</td>\n",
       "      <td>₹ 249</td>\n",
       "      <td>https://images.bewakoof.com/t320/the-chibi-cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Daffy Awesome Half Sleeve T-Shirt (LTL)₹ 24954...</td>\n",
       "      <td>₹ 249</td>\n",
       "      <td>https://images.bewakoof.com/t320/daffy-awesome...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  Price  \\\n",
       "0  Believe In Miracles Half Sleeve T-Shirt Bold R...  ₹ 199   \n",
       "1  Proud To Be Indian Half Sleeve T-Shirt - Bold ...  ₹ 149   \n",
       "2  All We Have Half Sleeve T-Shirt Meteor Grey₹ 5...  ₹ 549   \n",
       "3  Stay Classy Minnie Half Sleeve Printed T-shirt...  ₹ 199   \n",
       "4  Hotter Than Hell Half Sleeve T-shirt₹ 199599₹1...  ₹ 199   \n",
       "5  Jerry Relax Half Sleeve Printed T-Shirt (TJL) ...  ₹ 999   \n",
       "6  Sweet Sass Half Sleeve T-shirt (DL)₹ 199799₹17...  ₹ 199   \n",
       "7  More Reasons Boyfriend T-shirt₹ 349799₹319For ...  ₹ 349   \n",
       "8  The Chibi Cat Half Sleeve Printed T-Shirt₹ 249...  ₹ 249   \n",
       "9  Daffy Awesome Half Sleeve T-Shirt (LTL)₹ 24954...  ₹ 249   \n",
       "\n",
       "                                              Images  \n",
       "0  https://images.bewakoof.com/t320/believe-in-mi...  \n",
       "1  https://images.bewakoof.com/t320/proud-to-be-i...  \n",
       "2  https://images.bewakoof.com/t320/all-we-have-h...  \n",
       "3  https://images.bewakoof.com/t320/stay-classy-m...  \n",
       "4  https://images.bewakoof.com/t320/hotter-than-h...  \n",
       "5  https://images.bewakoof.com/t320/jerry-relax-h...  \n",
       "6  https://images.bewakoof.com/t320/sweet-sass-ha...  \n",
       "7  https://images.bewakoof.com/t320/more-reasons-...  \n",
       "8  https://images.bewakoof.com/t320/the-chibi-cat...  \n",
       "9  https://images.bewakoof.com/t320/daffy-awesome...  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "df= pd.DataFrame({'Name': names, 'Price':Price, 'Images':images})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
